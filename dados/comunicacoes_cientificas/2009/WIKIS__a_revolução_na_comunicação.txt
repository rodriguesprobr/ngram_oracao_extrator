WIKIS: a revolução na comunicação


RESUMO
A Internet viabilizou a comunicação entre múltiplos agentes em tempo real, reduziu a
distância entre autor e leitor e provocou a crise do paradigma que trata a comunicação como
transmissão de mensagens. No início, porém isto era pouco perceptível, pois textos e “links”
ainda eram definidos por “autores”. Aos leitores restava escolher entre caminhos
apresentados. A tecnologia Wiki, uma das primeiras expressões do que se chama de Web 2.0,
recuperou a lógica descentralizada do Hipertexto, superando a separação entre autor e leitor.
Ela é apenas uma primeira manifestação de um tipo de tecnologia, que viabiliza a interação e
a colaboração como elemento essencial da produção de conhecimentos. Os conceitos e
paradigmas usados pelas Ciências da Informação e pela Comunicação foram eficientes para
pensar a comunicação intersubjetiva. Mas não permitem abordar os fenômenos que aparecem
com a ampliação da complexidade. Para isto, precisamos redefinir conceitos e paradigmas
criados para estudar sistemas fechados e não os sistemas abertos e complexos que
vivenciamos hoje. A Internet sincronizou práticas sociais diversas em uma única rede criando
situações de grande dinamismo. Ocorre que se os conceitos e metodologias usados são bons
para sistemas estáveis, com elementos e relações finitas, eles não permitem abordar uma
realidade cambiante, com dinâmicas simultâneas, em escalas, tempos e espaços diversos. Em
sistemas complexos e abertos, a comunicação não pode ser vista, apenas, como troca de
mensagens. Neles, as relações são múltiplas e diversas, ocorrendo simultaneamente por
diversos “canais”, onde discurso e relações intersubjetivas são apenas parte do processo
comunicacional. Não existe “fluxo” de informações, mas sincronização entre elementos
diversos, cada qual condicionado e condicionando outros com suas constrições. Este artigo é
parte da pesquisa do Núcleo de Experimentação de Tecnologias Interativas (Next) sobre
tecnologias interativas. Nele apresentamos a tecnologia Wiki, as mudanças de cultura que ela
impulsiona e algumas notas para revisão dos conceitos comumente usados.
Palavras-Chaves: 2.0, Wiki, Hipertexto; Processamento de Informações; Teoria de
Comunicação; Sistemas Complexos; Internet

1 INTRODUÇÃO
Ao conectar um número ilimitado de repositórios de informação e viabilizar um
processo de comunicação de múltiplos agentes em tempo real, o advento da Internet colocou
alguns problemas teóricos e práticos novos para os pesquisadores em Ciência da Informação e
Comunicação.
Com o surgimento e desenvolvimento do computador e com a criação do Gopher no
início da Internet, o Hipertexto começou a se mostrar como uma possibilidade concreta para
concretizar o sonho do Mundaneum, de criação de uma Biblioteca Universal. Mas o Gopher ainda trazia uma estrutura centralizada, em forma de árvore e subdivisões sucessivas,
refletindo hábitos de processamento centralizados, característicos de sistemas simples;
sistemas fechados criados para tratar volumes finitos de informação.
O advento da WorldWideWeb (WWW), descentralizada, permitindo estabelecer todo
o tipo de relações e incorporação de informações, abriu novas possibilidades. Entretanto, por
mais que a Web, a capacidade de processamento ainda era limitada, as tecnologias não
estavam maduras, e, principalmente, os hábitos culturais anteriores ainda mantinham a
decisão nas mãos do “autor”. Os “links” eram definidos pelo criador das páginas e para o
leitor restava apenas a possibilidade de escolher entre os caminhos apresentados...
A tecnologia Wiki1, uma das primeiras expressões do que se convencionou chamar de
Web 2.0, recuperou a lógica descentralizada do Hipertexto, superando a separação entre autor
e leitor. Separação que começa a ser borrada quando é possível a qualquer um modificar o
texto, ou, a partir de uma palavra ou imagem, em algum ponto qualquer da página, estabelecer
relações com outros mundos e informações que lhe for conveniente, abrindo sua própria
janela e colocando o seu modo de ver.
Esta lógica, inaugurada pelos Wikis e que se desenvolve com a Web 2.02, abre a
possibilidade de surgimento de processos emergentes e põem em questão determinados
conceitos e paradigmas.

Em "Ferramentas Web2.0 para iniciantes em Gov 2.0", encontramos uma descrição do potencial das
ferramentas Web 2.0 para melhorar a qualidade e alcance das conversas entre governos e cidadãos. Abaixo o
texto que se refere a Wikis (http://insightgov20.wikispaces.com/, acesso em 14/09/2009, tradução Correa,
Kathia):
Wikis são um tipo de software colaborativo em que todos os participantes podem adicionar / editar / excluir
partes de um conteúdo que é compartilhado. Eles estendem o alcance da ação política tradicional, aproveitando o
conhecimento e a criatividade de uma comunidade de participantes para além da pequena elite que normalmente
se envolve no processo político. Este maior engajamento colaborativo pode levar à resultados de políticas mais
participativas e representativas, ao mesmo tempo em que compartilha a propriedade do conteúdo. Wikis
permitem aumentar as formas de participação já que as pessoas podem escolher quais as participações que lhe
são mais atraentes (apoio à pesquisa, elaboração de trabalhos originais, participação em debates, correção da
ortografia e da gramática). Isso tende a elevar a qualidade das contribuições individuais, pois elas são
conseqüência dos interesses de cada um. Wikis também armazenam as revisões das contribuições dos
participantes proporcionando um avanço significativo em relação colaboração de documentos tradicionais. As
mudanças entre cada versão original e a versão final podem ser revistas ordenadas por data ou por contribuição.
As Limitações: Wikis podem ser complicados para quem nunca utilizou. Além disso, os wikis não vêm com uma
estrutura pré formatada, e é necessário que os moderadores orientem a participação e em algumas situações
demonstrem caminhos. Wikis apresentam uma nova forma de trabalhar e, como tal, podem exigir apoio à
mudança de gestão para aplicação em locais de trabalho mais tradicionais.
2
Está em gestação uma tecnologia chamada de Google Wave, que usa a mesma lógica do que o Wiki, mas que
permite que um conjunto de pessoas trabalhe simultaneamente não apenas em textos, mas em qualquer forma de
arquivo (imagens, texto, música, etc), capaz de se conectar automaticamente a bancos de dados e incorporar seus
dados ao que está sendo produzido coletivamente, que será lançada talvez no ano que vem e que pode servir
como uma radicalização e entrada na maturidade, das tecnologias Web 2.0.

2 UMA CRISE DE PARADIGMAS
Um conjunto de conceitos teóricos e paradigmas se afirmaram na ciência pelos
resultados que foram capazes de promover ao longo de décadas. Ocorre que estes paradigmas
e conceitos foram produzidos para responder a uma lógica de sistemas simples ou fechados, e
não para sistemas abertos e complexos com capacidade de processar informações e
estabelecer relações em número infinito, como ocorre nas sociedades que foram se
construindo a partir da última metade do século passado.
A sociedade da informação é ao mesmo tempo causa e expressão desse processo. O
desenvolvimento da espécie humana, o seu crescimento e a sua interligação promoveram um
incremento de complexidade ao criar redes de relações de grande extensão, em escala global e
em praticamente todo o tipo de atividade. Com a criação da Internet tivemos um salto de
qualidade: se inicia um processo de sincronização de um número cada vez maior de práticas e
sistemas diversos, que se fundem em uma única rede, capaz de atrair, organizar e integrar
todo o tipo de atividade.
Esta mudança fundamental exige uma revisão teórica profunda. Os instrumentos
conceituais e as metodologias que usamos são bons e eficientes para estudar e formular
teorias e práticas para sistemas simples e fechados, povoados por elementos e relações em
número finito. Mas eles não são capazes de abordar sistemas abertos e uma realidade onde
tudo muda, muito rapidamente, a partir de dinâmicas simultâneas, em escalas, tempos e
espaços diversos.
O próprio conceito de ciência, expresso no paradigma clássico, que considera a
realidade como algo “objetivo”, exterior e anterior ao “conhecimento”, não consegue dar
conta da dinâmica dos processos e relações impulsionados por novas práticas da espécie
humana, que abrem terreno para uma ciência reflexiva, onde não é mais possível separar
sujeito e objeto.
Na mecânica newtoniana que ofereceu a base da ciência clássica, o sujeito está
separado do objeto. Nela, as objetividades (objetos) estariam livres de limitações epistêmicas
intrínsecas (subjetividades), aparecendo como realidades absolutas, auto-suficientes e
completamente independentes da ação do sujeito epistêmico. A verdade foi definida como
adequação à realidade, e se acreditava que ela seria alcançável conjugando uma prova teórica
- coerência do discurso - e uma prova empírica - adequação à realidade. No entanto, já
sabemos que ambas as provas são paradoxais, porque são auto-referentes: a teórica exige pensar o pensamento, o que nos leva ao princípio da incompletude de Goedel3; a empírica
exige medir a matéria com instrumentos feitos de matéria, o que nos leva à indeterminação de
Heisenberg4. (IBAÑEZ, 1988)
A cibercultura é uma emergência em curso na sociedade humana, em uma época
caracterizada pela incerteza, onde a realidade é construída pela ação de múltiplos e infinitos
atores. Essa realidade, acêntrica pela sua própria gênese, não pode ser tratada como uma
totalidade estável, passível de ser medida e verificada (e muito menos ser dividida e
recomposta). Isto porque ao “observá-la” conseguimos ver apenas os aspectos que foram
considerados em nossa pergunta, a partir de um ponto de vista particular, ou seja, aqueles
aspectos que podem ser observados pelos instrumentos que escolhemos.
A Internet estabeleceu relações entre um número ilimitado de repositórios de
informação e práticas diversas, viabilizando um processo de comunicação de múltiplos
agentes e em tempo real. Reduzindo a distância entre autor e leitor, ela provocou a crise de
um paradigma que se apóia numa concepção que, mesmo com todas as suas ressalvas, não
fugia à visão da comunicação como um processo de transmissão de mensagens, pautado pela
centralização e controle.
Por outro lado, a necessidade de processamento de grandes volumes de informação
demonstrou que não era possível viabilizá-lo com os métodos e técnicas tradicionais de
indexação e classificação. Estes métodos não dão conta de processar e organizar a imensa
quantidade de documentos, que cresce cotidianamente e que abrange todo tipo de disciplina.

A separação autor e leitor
Uma das características mais marcantes da comunicação nos sistemas simples ou
fechados é a centralização da produção e processamento de informações, com a manutenção
do controle nas mãos do autor.
A pouca flexibilidade das tecnologias de imprensa, que exigem um suporte material
para o registro das informações, fizeram com que os sistemas de informação fossem
organizados dessa maneira, com o processamento de informação controlado por quem tem
recursos para viabilizá-lo. Além disso, por sua pouca capacidade de processamento, esses sistemas só podiam trabalhar com um número limitado e finito de informações e com
interações restritas, organizando o processo de comunicação de uma maneira característica e
específica.
Estes sistemas, que podemos caracterizar como “Sistemas Simples de Informação”,
assumem características muito precisas e particulares para se tornarem viáveis, mesmo com
recursos limitados. Eles são sistemas fechados (circunscritos a possibilidades pré-definidas e
especificadas), especializados (organizados para ações e objetivos específicos), homogêneos
(de maneira a simplificar o processamento) e forçados a considerar “ruído” e desprezar tudo
que não é especificamente relacionado com seus objetivos. O resultado destas constrições é
um sistema estático, com opções pré-determinadas, onde não existe a possibilidade de ocorrer
algo de novo (isto é, algo não especificado com anterioridade), com fluxos claramente
definidos e com baixa possibilidade de processamento.
A Informação neste tipo de sistema é identificada como “mensagem” ou “conteúdo”, e
a Comunicação entendida como um processo de “transferência de informação” do “emissor”
(“autor”) para o “receptor” (“leitor” ou “expectador”), através de uma espécie de canal (a
“mídia”). Não é por acaso que esta é a idéia de comunicação que vemos no senso comum (de
“transferência” de informação). Ela também prevalece nos meios acadêmicos, apesar dos
refinamentos teóricos para dar conta de elementos que surgem nos processos comunicativos e
que não podem ser explicados por este modelo, tais como a emergência de significados não
produzidos pelo “autor”, os processos interativos, etc.
Esta concepção traz uma série de conseqüências:
A primeira delas diz respeito ao próprio conceito de informação. Em lugar de a
informação ser entendida como resultado da construção de diferentes agentes, como um
“evento” e algo que não foi pressuposto. Ela é considerada como algo objetivo, concreto,
quase material, expressão e representação de uma verdade “objetiva”, absoluta e universal. A
informação deixa de ser percebida como um ato de distinção, expressão de um determinado
ponto de vista e de uma maneira particular de olhar.
A segunda conseqüência é que, pela pouca maleabilidade das tecnologias de imprensa,
a organização da informação obedece a padrões que buscam uma certa permanência, o que
resulta na rigidez de um sistema de classificação e indexação estático, onde se cristalizam
determinados “significados” e relações entre os agentes, e onde são inviabilizadas outras
possibilidades não previstas com anterioridade.
A terceira conseqüência é que a capacidade limitada de processamento, leva ao uso de
uma estratégia de redução do quadro de informações considerado. Somente são levados em conta os elementos julgados “determinantes”, por estarem direta e imediatamente envolvidos
com os objetivos do sistema, descartando-se todos os outros, que são tratados como
secundários e vistos como “ruído5”.
A última conseqüência que registramos, é justamente a cristalização de papéis no
processo comunicativo: a separação entre emissor e receptor, com o controle dos primeiros
em detrimento dos segundos, aos quais na melhor das hipóteses é reservada a função de
fornecedores de feedback.
Esta concepção tem características e conseqüências que passam desapercebidas
quando se trabalha com um número de variáveis e elementos determinados e restritos. As
variáveis consideradas “secundárias” podem ser desconsideradas em sistemas simples de
informação, onde é possível preservar uma certa estabilidade e homogeneidade. Mas quando
o sistema se amplia em número de elementos e relações, adquirindo características de um
sistema complexo, quando as variáveis e dinamismo do sistema tendem ao infinito, esse
procedimento simplesmente se inviabiliza.

Comunicação e Informação em Sistemas Complexos
Em sistemas complexos e abertos, por suas características dinâmicas e pela infinidade
de elementos e relações que deles fazem parte, a comunicação não pode ser tratada como nos
sistemas simples. Neles, não é possível isolar e reduzir o processo de comunicação a um único
de seus aspectos, as relações intersubjetivas, que se verificaria com o envio e troca de
mensagens entre uma fonte e um receptor através de um canal determinado. Nesses sistemas,
a comunicação e as relações entre diferentes agentes, são múltiplas e de natureza diversa,
ocorrendo simultaneamente em variadas direções (através de múltiplos “canais”) e
produzindo os mais diferentes tipos de informação ao mesmo tempo. Neles, a comunicação
não pode ser reduzida exclusivamente a relações intersubjetivas; o discurso é apenas um de
seus elementos e nem sempre o mais importante.
Nos sistemas complexos, a informação não pode ser entendida como representação
estável de algo exterior a ela. O importante nesse tipo de sistema não é a pretensa apreensão
da “realidade”. A verdade de uma representação esta relacionada a um ponto de vista
específico a partir do qual ela se constrói. Em outras palavras, não existe uma verdade
absoluta. A verdade esta relacionada a um sistema particular que gerou aquela representação,
a partir dos instrumentos que a constituíram. Nos sistemas complexos as representações podem ser múltiplas (e, portanto, podemos ter muitas verdades), pois o sistema não é
homogêneo e não se situa em um tempo e espaço único. A informação tem valor para um
sistema particular e específico e não pode ser entendida como “conteúdo”, pelo menos como
“conteúdo verdadeiro“ em termos absoluto.
Por isso afirmamos que, nesses sistemas, a informação não pode ser tratada como algo
quase material, mas deve ser entendida como uma emergência. Nesse caso não existe um
“fluxo” de “mensagens”, mas um processo de sincronização entre diferentes atores6, uns
condicionando os outros com suas constrições, que, no final do processo, produzem algo que
não existia antes. É neste potencial de transformação que está o seu valor.
O importante nesse tipo de sistema não é o “conteúdo”, mas o ato de distinção e o seu
potencial de criação do novo. Nesse ato, os diferentes agentes se sincronizam e se modificam
criando novas realidades, diferentes da anterior e ao mesmo tempo diferentes para cada um7.
É neste potencial de transformação que está o seu valor.

Informação e Interação
Esta rápida explicação já nos permite entender que existe uma diferença entre o que
pode se definir como “valor” da informação nos sistemas simples ou nos sistemas complexos.
Costuma-se dizer que a “informação vale ouro”, o que podemos aceitar em sistemas simples,
onde temos uma carência de informações (vistas como representações “verdadeiras“).
Nos sistemas complexos, a interação é a rainha do processo. Para abordá-los
precisamos ver a informação como propriedade da relação de sistemas diferentes, o que só é
possível se ela for entendida como um processo de interferência, de in-formação recíproca
entre sistemas diferentes, situados em parâmetros espaços-temporais diversos, mesmo que se
“encontrem” e se ”atualizem” em um espaço e tempo específico comum, quando ocorre um
processo de emergência.
Esta in-formação recíproca não se realiza através do envio de mensagens e respostas
sucessivas no tempo e no espaço, mas conforme nos propõe Navarro, por um processo de
sincronização de constrições8. A noção de constrição9 entre sistemas é equivalente à noção de informação como aquisição de uma nova forma particular por parte de uma realidade.
Ressalte-se que há neste ponto uma identificação entre informação e surgimento de novas
distinções.
Dois sistemas se in-formam mutuamente quando deixam de ser
independentes e se convertem em causalmente dependentes, quando seus
tempos se cruzam, entram em contato, e geram um tempo novo no qual é
possível e se formam seqüências de sucessos, inexistentes em seus tempos
prévios individuais. (Navarro, 1977)

Quando isto ocorre cada um ou os vários sistemas podem ser apenas perturbados e, ao
deixarem de se sincronizar, um ou ambos retomarem a sua trajetória anterior; ou podem sofrer
uma modificação irremediável em sua trajetória,.
A sincronização de constrições pode vir a se constituir em uma única rede de
acontecimentos não contínuos, onde diferentes seqüências “podem se manter independentes
em todos os momentos que não sejam aqueles nos quais se cortam, nos quais entram em
dependência causal” (Navarro, 1994). Em outras palavras, podem continuar independentes
fora daqueles momentos nos quais se manifestam em um mesmo espaço e tempo, no terreno
do atual, quando aparecem sujeitos e de certa forma hegemonias. Isto é, quando um ponto de
vista se “impõe” ao sistema, ainda que de forma efêmera e passageira. Nos outros momentos
temos um fenômeno de concorrência causal, quando as pré-condições de um certo sucesso
podem ser geradas de maneira independente e se manifestar de maneira diversa.
No modelo acima descrito não existe mensagem. Nada é transferido de um para outro
sistema. A informação não é algo tangível e quase material. De certa forma ela é quase um
evento, um processo de emergência no tempo e no espaço de algo que não se situa nele. Ela
consiste na descoberta de novas possibilidades de relação e não na transmissão da relação já
descoberta.
Esta abordagem permite entender como o processo de comunicação possui condições
de gerar algo novo e não apenas transferir algo de um lugar para outro do sistema. Permitenos também lidar com ambientes assíncronos, fragmentários, heterogêneos, descontínuos e,
principalmente permite entender, enfim, o processo interativo como um ato de criação, e a
informação como resultado de uma negociação e sincronização entre diferentes.
duas ou mais seqüências de sucessos, mutuamente independentes – cada uma delas constituída por sucessos
causalmente conectados – entram em contato” de forma que ambas modificam-se mutuamente (Navarro, 1994).

3 A REVOLUÇÃO DOS WIKIS E DA WEB 2.0
A revolução iniciada pela tecnologia Wiki foi criar dispositivos de interação virtual
que viabilizam a comunicação como um processo de sincronização entre diferentes e
múltiplos agentes e artefatos10, e não como “transmissão de mensagens” ou para “difusão de
conteúdo”. Em lugar dos diferentes usuários trocarem mensagens, eles se debruçam sobre um
mesmo trabalho e o desenvolvem coletivamente. De certa maneira os Wikis anunciaram as
tecnologias chamadas de Web 2.0, que consolidam um novo paradigma.
Com a tecnologia Wiki, ao contrário das tecnologias da 1ª fase da Internet e do
Hipertexto tradicional, em que o autor publica e os outros lêem, se pode superar a divisão
entre emissor e receptor, o que, por sua vez, tem como conseqüência a aproximação entre
“ação” e “pensamento”.
Mesmo nos sistemas simples ou na utilização tradicional do hipertexto, a comunicação
se estabelece como um processo de sincronização a partir das constrições colocadas pelos
diferentes atores. Mas as tecnologias anteriores reduzem a amplitude deste processo de
sincronização. As constrições do emissor, seus pontos de vistas e suas características
particulares tendem irremediavelmente a prevalecer, pois ao leitor é apenas reservado o papel
de aceitar ou não as opiniões do emissor e oferecer um feedback, em geral indireto.
Evidentemente que isto influencia aos autores, no mínimo porque eles pretendem continuar
influindo e sendo lidos. Neste sentido podemos dizer que ambos se in-formavam, isto é, que
mesmo nos sistemas simples, eles se modificavam mutuamente. Mas no caso das tecnologias
Wiki, o processo de sincronização entre os diferentes agentes pode ocorrer livremente, de
modo direto, em diversos sentidos e em tempo real.
A tecnologia Wiki e outras que cumprem a mesma função, ainda são adolescentes. A
interação ocorre basicamente através de textos. A utilização de imagens, vídeos, sons, etc,
são ainda incorporadas da mesma maneira que se fazia com as tecnologias tradicionais, sob a
forma de objetos que servem para “ilustrar” os textos ou servir de fundo. O elo de ligação
entre todos os elementos ainda se dá basicamente através da narrativa organizada pelo texto.
Mas podemos imaginar a lógica destas tecnologias sendo usadas em ambientes de realidade
virtual, onde a sincronização acontecerá na modificação de uma “realidade” em três
dimensões e os “links” serão passagens entre mundos e espaço/tempos diversos.
O grande problema que nós viveremos será cultural e não tecnológico
Uma preocupação levantada freqüentemente, quando se abre a possibilidade de
participação do usuário, por exemplo, é a possibilidade de pessoas escreverem “mentiras” e de
vândalos “destruírem” o que foi feito. O habito de ter intermediários que controlem, garantam
e policiem o processo leva ao descrédito sobre a possibilidade de que algo possa dar certo
onde todo o mundo tenha liberdade para “fazer o que quer”.
Já temos, no entanto, muitos exemplos que comprovam a eficiência da tecnologia
Wiki. Desde que o sucesso da Wikipédia se tornou público, a tecnologia Wiki tem sido
experimentada em diversas áreas. Já existem Universidades que organizam toda a sua
produção e acervo em plataformas Wikis;

Empresas que organizam toda sua memória

institucional e técnica; Redes de Pesquisadores que estruturam sua atividade e suas
comunidades em torno de Wikis, entre muitas outras iniciativas. Mas a grande experiência
vitoriosa dos Wikis em sua fase inicial foi, sem dúvidas, a Wikipédia (Ver anexo: A
experiência da Wikipédia).
Alguns segredos estão na origem destes resultados:
1) Em primeiro lugar está o fato de que serviços como a Wikipédia oferecem um
resultado inestimável aos seus milhões de usuário. O fato de sentirem-se em à vontade nestes
dispositivos e os perceberem como seus, porque lhes são úteis e neles têm total liberdade para
participar e intervir, os tornam defensores do serviço. Eles se encarregam cotidianamente de
corrigir e aperfeiçoar o sistema. E são milhões de “validadores” que os defendem contra a
atuação de um pequeno punhado de “vândalos” e “mentirosos”.
Como afirma Balbino (2007):
A relação entre o número de verbetes que possui e os que de fato foram
atingidos por vândalos é insignificante, além de plenamente reversível.
Os danos causados por tais ataques não são nem um pouco relevantes e
não há indicativos de que eles o sejam no futuro, simplesmente porque é
impossível um movimento de negação que consiga modificar um
significativo número de verbetes, muito menos de forma permanente (um
apresentador da televisão americana também tentou instigar sua grande
audiência a fazer isto, sem sucesso).

2) Em segundo lugar o segredo dos ambientes interativos criados pela Web 2.0 está na
utilização de processos característicos de sistemas complexos, onde a dinâmica de
sincronização pode gerar realidades novas, inexistentes anteriormente. Nestes ambientes
regulados por normas e protocolos relativamente simples e aceitos por todos, com a intensa
interação viabilizada pela simplicidade dos mecanismos e muita meta-informação orientando
ao usuário que o necessite, podem ser criados processos emergentes bastante sofisticados.
Estas normas e protocolos se transformam numa verdadeira gramática deste imenso

Hipertexto em que se transformou a Internet, criando regras simples11 apoiadas na experiência
de colaboração para regular as coisas e garantir que funcionem.
3) Em terceiro lugar, através de um processo de constantes aperfeiçoamentos, é concebida e
criada uma grande variedade de mecanismos técnicos que defendem e regulam o dispositivo,
tais como sistemas de backups, sistemas de comentários, espaços de discussão, além do fato
de que todas as versões e cada modificação ficam registradas. Some-se a isto uma série de
voluntários sempre a postos para defender o sistema.
4 APROXIMAÇÃO DE AÇÃO E PENSAMENTO.
Mas as novas práticas que nos trazem os Wikis e as tecnologias Web 2.0, não se
limitam a transformar seus usuários em agentes. Ao modificar a relação entre autor e leitor,
fundindo-os, ela termina por aproximar também “ação” e “pensamento”, viabilizando sua
utilização em atividades de gestão e coordenação.
Na verdade embora a tecnologia Wiki tenha se tornada conhecida apenas recentemente
com a Wikipédia e basicamente associada a atividades de publicação, ela surgiu como um
dispositivo de organização e gestão colaborativa de documentos, utilizado pela comunidade
de software livre para coordenação de atividades, documentação de programas e criação de
cursos e tutoriais.
O pressuposto da gestão é que para obter maior eficiência e utilizar menos recursos,
devemos conseguir a maior coordenação possível entre os diferentes agentes. Por isto, em
geral, se busca ter a visão mais completa possível de todos atores, recursos e processos
envolvidos, procurando estabelecer um plano, o mais detalhado que se possa, para prever
todas as ações que serão colocadas em curso. O passo seguinte é estabelecer uma cadeia de
ações e responsabilidades, envolvendo os diferentes atores no tempo e no espaço dentro de
limites claramente estabelecidos e controlados pelo gestor. A centralização e a hierarquia de
funções e tarefas são instrumentos fundamentais para o seu sucesso.
No entanto, se este procedimento e centralização trazem eficiência e cumprem seus
objetivos em situações e sistemas de pouca complexidade, onde praticamente todas as
variáveis relevantes podem ser previstas e especificadas, isto não ocorre da mesma maneira
quando se incrementa a complexidade.


Quando aumenta a complexidade, torna-se impossível ter em conta todas as variáveis
do processo. As próprias modificações do cenário influenciam o comportamento dos agentes.
Os recursos são canalizados para suprir necessidades que não podiam ser previstas, por terem
sido geradas pela própria colocação em marcha das ações concebidas anteriormente. Neste
tipo de ambiente o gestor tem dificuldades em saber de tudo que ocorre e em manter a
disciplina, a hierarquia e a coordenação do processo.
As novas tecnologias de informação e comunicação criaram possibilidades novas para
a coordenação de atividades e atuação de gestores em ambientes mais complexos. No
primeiro momento, no entanto, como já afirmamos, elas foram utilizadas a maneira antiga:
como instrumentos para estender os olhos e os braços do planejador e do gestor, ampliando a
informação e a comunicação entre todos os parceiros e criando elementos de controle para sua
ação e para feedback. Toda a filosofia dessa geração de tecnologias era ampliar o máximo
possível a capacidade e eficiência do gestor, garantindo a centralização. Foram então criadas
ferramentas (Outlook, Lótus, Note, Organize, etc.), que cumprem o papel de eficientíssimas
secretárias. Estabelecido o plano, definidas as responsabilidades e funções, elaboradas as
metas, autorizações e permissões, elas ampliam a comunicação e o controle das atividades
desenvolvidas pelos membros de um projeto e permitem a criação de relatórios.
Mas estes procedimentos, que apenas criam rotinas e mecanizam as ações de gestão
feitas anteriormente, rapidamente se mostram inoperantes para gestão de grandes sistemas.
Quando se amplia a complexidade, o número de elementos cresce de maneira exponencial e
tudo muda constantemente.
Hoje, em particular na Internet, vivenciamos uma nova fase e um novo tipo de
resposta a este tipo de problema através da criação de sistemas colaborativos, interativos,
descentralizados e emergentes. Neste caso, o que se define é muito mais uma direção do que
um roteiro dos passos que serão dados no processo. Quando são eliminadas as figuras do
“agente” e “não agente”, o que se abre é uma nova etapa para a gestão.
As tecnologias Web 2.0, viabilizando a sincronização de diferentes agentes, oferecem
uma base para a criação de sistemas colaborativos e de compartilhamento de recursos. Ela
favorece a construção coletiva e a participação desde a fase inicial de planejamento, assim
como a produção coletiva de conhecimentos e a coordenação de atividades.
Combinada com outros sistemas e ferramentas interativas elas tendem a penetrar em
todo o tipo de atividade humana, transformando as nossas sociedades e nossa vida.

Mesmo que a tecnologia Wiki ainda seja utilizada basicamente para a produção de
conhecimentos, publicação e constituição de uma memória coletiva, a sua utilização para
outros fins e em particular para atividades de coordenação e gestão dá seus primeiros passos12.
O Núcleo de Experimentação de Tecnologias Interativas (Next), cujas pesquisas
originaram este artigo, utiliza a tecnologia Wiki em seu Dispositivo de Interação Virtual (DIV
- construído com tecnologias Web 2.0), para fins de planejamento e coordenação de suas
atividades (http://www.next.icict.fiocruz.br/wiki),
Para facilitar o processo, pode-se configurar o Wiki para que, a cada intervenção de
algum de seus participantes, sejam enviadas mensagens aos outros avisando que há uma nova
colaboração.
Do mesmo modo, temos experiências de Wikis sendo utilizados para organização de
cursos, que, além da informação institucional e de organização da memória coletiva, são
eficientes para organização de atividades gerais de disciplinas, ou específicas dos alunos e
professores, assim como para realização de trabalhos escolares13.
Na coordenação de atividades mais importantes e complexas, podem-se configurar
filtros específicos de quais avisos são enviados para quem, assim como podem ser integradas
outras tecnologias como rede social, comunicadores, agendas, etc., configurando-os segundo
as características específicas e dos projetos a serem coordenados e acionados.
5 PROCESSOS EMERGENTES
Não será possível entender a eficiência e capacidade de autodefesa dos sistemas
interativos, se não compreendermos uma das características mais importantes dos sistemas
complexos: os processos de emergência.
A ciência tradicional nos fez acreditar que a centralização e a hierarquia são a única
possibilidade de obter coordenação, coesão e garantir a produção coletiva de um
agrupamento. Nos sistemas complexos, que não suportam centralização, ao contrário, são os
processos emergentes colocados em marcha pela interação que dão coesão à comunidade e
viabilizam sua produção.

Usamos aqui o conceito de emergência apontado por cientistas empenhados em
entender sistemas que usam componentes relativamente simples para construir inteligência de
nível mais alto, onde agentes locais desenvolvem ações seguindo regras simples que são
capazes de gerar estruturas surpreendentemente complexas (Johnson, 2001).
(Os sistemas complexos) ”resolvem problemas com o auxílio de massas de
elementos simplórios, em vez de contar com uma única ‘divisão executiva
inteligente’. São sistemas bottom-up (de baixo para cima), e não, top-down
(de cima para baixo). Pegam seu conhecimento a partir de baixo. Em uma
linguagem mais técnica, são sistemas adaptativos complexos que mostram
comportamento emergente. Neles, os agentes que residem em uma escala
começam a produzir comportamento que habitam uma escala acima deles:
formigas criam colônias; cidadãos criam comunidades; um software simples
de reconhecimento de padrões apreende como recomendar novos livros. O
movimento de regras de nível mais baixo para a sofisticação de nível mais
alto é o que chamamos de emergência” (p. 14) (Johnson, 2001).

Estes processos emergentes, não são o resultado do desdobramento dos conhecimentos
e práticas particulares dos elementos que o compõem. Com suas características de autoorganização, eles são capazes de construir conhecimentos novos e práticas coletivas, criando e
garantindo a coesão através de processos de sincronização que constituem novas realidades.
Os processos emergentes, como afirma Johnson, se desenvolvem a partir de regras
simples. No caso da Web 2.0, estas regras ou estão embutidas no mecanismo tecnológico, ou
são divulgadas através de normas de uso, regras de convivência, orientações do que pode e o
que não deve ser feito, que estruturam uma verdadeira gramática14 da linguagem nos Wikis.
Uma idéia destas regras pode ser vista, por exemplo, em “Normas de Conduta” da
Wikipédia Lusófona onde são definidos Princípios de Etiqueta na Wikipédia, Como Evitar
Abuso nas Páginas de Discussão, Como resolver Conflitos e “O Que Não se Deve Fazer”
(Ver ao final – Links sobre Wikis).
Os mecanismos de controle da ação dos usuários, por sua vez, estão diretamente
relacionados ao tamanho do universo do sistema. Quanto mais pessoas estiverem usando o
Wiki, menor deve ser, em princípio, a necessidade de níveis de controle, pois ele é feito pela
própria comunidade. Assim, um Wiki muito pequeno costuma necessitar um nivel maior de
controle para impedir autores anônimos e evitar vandalismo15. Por outro lado, a maioria dos

14

Gramática (do Grego transliterado grammatiké, feminino substantivado de grammatikós), é a "arte de ler e de
escrever", (pelo Latim grammatica, com o mesmo significado, Ferreira, Aurélio Buarque de Holanda). Segundo
o Dicionário: “é o conjunto de regras individuais usadas para um determinado uso de uma língua (...)".
15
Uma série de técnicas são utilizadas para defesa do dispositivo. Muitos dos principais Wikis tem como limitar
o acesso à publicação. Alguns destes mecanismos possibilitam banir usuários do processo de edição pelo
bloqueio do seu endereço particular na Internet (endereço IP), ou o seu nome de usuário, quando disponível.
Como solução rápida, alguns Wikis permitem que, em momentos de dificuldades o banco de dados seja alterado
Wikis públicos, que costumam ser grandes, dispensam qualquer tipo de registro ou
identificação.
Mas o principal elemento de controle são os chamados mecanismos de Validação
Social: Sistemas de aferição de opiniões, vontades e reconhecimento, e de decisão da
comunidade participante (Ver Santos e Ximenes, 2008). Pois como afirmou o hacker Eric
Steven Raymond:
"Havendo olhos suficientes, todos os erros são óbvios".
6 CONCLUSÃO
Por todo o dito até aqui, temos consciência de que as tecnologias Wiki, como as
tecnologias chamadas de Web 2.0 em geral, inauguram uma nova fase na Internet (ou reinauguram a Internet) recompondo algumas das utopias que aparecem já no seu início. Estas
Utopias não podiam se realizar anteriormente porque o grau de amadurecimento desta
tecnologia ainda não o permitia e principalmente porque a cultura da centralização ainda
conseguia manter o controle e frustrar as expectativas, tal como aconteceu com o Hipertexto
centralizado do Gopher e mesmo, em certa medida, com o Hipertexto unidirecional do WWW
inicial.
O Hipertexto produzido coletivamente com a tecnologia Wiki adquire uma textura
nova e rompe definitivamente com a narrativa linear. Para se viabilizar e cumprir seu papel
ele ganha uma nova forma, permitindo diferentes dimensões de espaço-tempo, viabilizando
diferentes pontos de vista e diferentes histórias:
O Hipertexto e seus links são apenas parte das possibilidades. Num texto
dinamicamente escrito e reescrito, por autores conscientes do seu poder de
influir na coletividade, o que temos é o surgimento também de camadas,
dobras, platôs, múltiplos, histórias (num sentido mais deleuziano). Para se
chegar a uma conclusão condizente com os objetivos de um Wiki, deve-se
não apenas seguir os links, mas acompanhar e interpretar a história, os
diversos momentos do texto que lá está” (Balbino, 2007).

Permitindo a convivência e interação de diferentes sujeitos em um mesmo texto, as
tecnologias que vem sendo criadas permitem superar de vez a separação entre autor e leitor...
O que fizemos com este artigo, foi apresentar a lógica da tecnologia Wiki e em
particular sua lógica e mudanças de cultura que ela traz ao romper com a separação entre
autor e leitor e criar condições para a ampliação dos conceitos de comunicação e informação,
para o modo apenas-leitura. Outros adotam uma política em que apenas usuários que tenham sido registrados
antes de algum corte arbitrário possam editar. Em geral, como o sistema registra automaticamente todas as
alterações, qualquer prejuízo criado por um "vândalo" pode ser revertido rápida e facilmente voltando para a
versão anterior.

adaptando-as aos problemas colocados pela ampliação da complexidade. A partir daí
avançamos algumas reflexões que podem servir a revisão de conceitos utilizados nas áreas de
comunicação e informação, para que se torne possível entender e abordar as modificações que
se processam com a introdução de tecnologias interativas e com a Internet. Estas reflexões
vem sendo feitas em nossa pesquisa e sentimos necessidade de debatê-las com nossos pares
para desenvolvê-las, aprofundá-las e retificá-las com vistas a aprofundar nossa compreensão e
intervenção sobre o processo em curso de desenvolvimento das transformações que
vivenciamos em nossa sociedade.
