
A AÇÃO DOS BOTS NO PROCESSO DE DESINFORMAÇÃO EM ELEIÇÕES E REFERENDOS
Modalidade da Apresentação: Pôster
Resumo: Apresenta o contexto atual onde agentes autônomos de informação (bots) participam do
processo de desinformação em eleições e referendos. O objetivo deste artigo é posicionar os robôs
como atores relevantes para o processo de desinformação e que já são suficientemente autônomos
para elaborar estratégias próprias para atingir suas metas. Para tanto, serão apresentados relatos
ocorridos no mundo real em que a participação de tais agentes autônomos na propagação de
informações falsas trouxe repercussões a sociedade. Sendo assim, foi realizada uma pesquisa
bibliográfica, qualitativa e exploratória, em fontes acadêmicas e sítios especializados em tecnologia de
credibilidade reconhecida. Desta forma, os bots vêm sendo utilizados para disseminar notícias
inverídicas e que com o acesso a grande quantidade de informação (big data), tais robôs estão sendo
mais seletivos e efetivos no processo de desinformação. A influência da manipulação promovida por
estes bots pode acontecer de forma localizada, sugerindo comportamentos de uma pessoa, até mesmo
em eventos maiores como eleições e referendos. Conclui-se que, com a ampliação da adoção da
Internet no cotidiano das pessoas, cada vez mais robôs farão a seleção/curadoria do conteúdo a ser
apresentado aos usuários e consequentemente o aumento da exposição dos mesmos a falsas
informações.
Palavras-Chave: Desinformação; Agentes Autônomos de Informação; Bots.

1 INTRODUÇÃO
A Internet nos dias atuais é povoada por uma série de atores movidos pelos mais
diversos interesses. Esta diversidade de participantes em rede promove novos comportamentos
informacionais que são amplamente divulgados em veículos especializados em tecnologia
publicados na imprensa e periódicos acadêmicos especializados. Novas maneiras de se
relacionar com pessoas, meios de se comunicar, regimes de trabalho e até mesmo hábitos de
compras se consolidaram com a combinação da Web e Smartphones. Entretanto, a participação
de robôs, doravante chamados de bots, vem aumentando na Internet a ponto de se tornar
comum a interação entre seres humanos e bots.
De acordo com Barth (2018) 53,1% do tráfego da Internet de 2017 foi realizado por bots.
Esses números são parecidos com aqueles apresentados por Fischer (2017) que sugeria que
51,8% do tráfego de 2016 foi realizado por robôs. Se agentes autônomos participam de maneira
tão ativa nos fluxos de informação em rede, pode-se prever que eles também estão envolvidos
em processos de desinformação. Chao e colegas (2017) sugerem que bots já assumam um papel
de protagonismo na disseminação de fake news nas mídias sociais.
É deste contexto que vem a motivação da pesquisa que tem como objetivo analisar a
participação dos bots no processo de desinformação que ocorre nas eleições. Uma vez que, a
Ciência da Informação já possui seu olhar para objeto desinformação, ainda se faz necessário
desenvolver esta visão na Internet e com atores não humanos. Este ainda é um trabalho em
andamento e a metodologia de pesquisa a ser adotada é um levantamento de referencial
teórico sobre desinformação, a visão da CI para os bots, e por fim, uma análise de casos sobre a
ação de bots em processos de desinformação e fake news. Este trabalho faz uma parte de uma


pesquisa mais ampla, dissertação de mestrado, que tem como objetivo analisar a participação
dos bots nas eleições brasileiras de 2018.
2 DESINFORMAÇÃO
Para Brito e Pinheiro (2014, p. 1) a exploração do termo desinformação na produção
científica da Ciência da Informação ainda se revela escassa. Pode-se remontar a origem das
pesquisas sobre desinformação na CI a partir de Capurro (1999, tradução nossa) onde este
afirma que “no domínio da ciência da informação existe a preocupação com a forma negativa,
a desinformação e seus derivados: mentiras, má interpretação, ilusão, erro, decepção”.
Zattar (2017, p. 288) afirma que “a noção de desinformação surge no contexto das
práticas de guerra, onde era utilizada como estratégia que permitia vantagens frente ao
adversário”. Conforme a mesma autora há três características que merecem ser observadas
quando tratamos de desinformação: (i) desinformação é informação; (ii) desinformação é uma
informação enganosa e (iii) desinformação não é uma informação acidentalmente enganosa.
Brito e Pinheiro (2014, p. 2 e 3) afirmam existir três significados para desinformação: (i) ausência
de Informação; (ii) informação Manipulada e (iii) engano Proposital.
Para Demo (2000, p.40 e 41) a informação manipulada encontra espaço em nossa
sociedade por cinco motivos: (i) a sociedade está em estado de desinformação seja porque a
informação disponibilizada é residual, oficial ou em excesso servindo ao objetivo oposto do
desejado; (ii) para o autor há informação de classe superior e inferior que depende do poder
aquisitivo e acesso a diversidade de fontes de informação; (iii) existe um excesso de “informação
imbecilizante” que é distorcida, fútil ou banal; (iv) os veículos de comunicação se distanciaram
da sua finalidade já que, de acordo com o autor, existe uma “apropriação privada” da
informação que segue interesses comerciais; por fim, (v) os novos meios de comunicação estão
disponíveis ainda a uma parcela privilegiada.
Quando se trata de desinformação nos meios digitais, Zattar (2017, p. 286) afirma que
esse fenômeno deve ser enxergado como uma prática informacional onde reside “questões que
envolvem a qualidade do conteúdo nas dinâmicas de busca e recuperação, dentre as quais estão
as notícias e informações falsas ou semifalsas, a desinformação”. Consoante afirma a autora
“muitos autores relacionam a desinformação ao desenvolvimento das tecnologias de
informação e comunicação e, especialmente, à Internet, que possibilita a participação de
múltiplos atores na produção e no uso de informações”.



Côrrea e Custódio (2018, p. 2) complementam que dentro da atual cultura digital este
fenômeno se apresenta com mais força, tendo em vista que, em ambientes como a web é
comum a disseminação de inverdades, em virtude do compartilhamento de conteúdo de forma
irrestrita e indiscriminada. Para os autores “essas inverdades vêm ganhando um espaço cada
vez maior no ambiente virtual, seja através da veiculação de notícias falsas (fake news), seja por
meio das chamadas ‘pós-verdades’ (post-truth) ”.
3 BOTS NA CI
Burkhardt (2017) afirma que bots são programas de Software automáticos que
executam tarefas repetitivas para coletar dados da Internet. Neste sentido afirma a autora, bots
podem automatizar o entediante e demorado processo de minerar informação de forma
eficiente, além de ter a capacidade de analisar os dados dos usuários com o intuito de manipular
opinião.
Thurler (2017) afirma que o papel das máquinas se transformou nos últimos anos e estas
não são mais apenas mediadoras da informação, se tornando agentes participativos que
impactam nas práticas de gestão do conhecimento. A autora remete ao Memex de Vannevar
Bush a formalização do desejo em criar formas de ampliar as potencialidades humanas, no que
tange as necessidades de informação, por meio de máquinas.
Entretanto, Dent (2007) aponta que as máquinas que participam dos processos de
informação não são baseadas em hardware (visão de Bush) e sim, são os agentes de software
(visão de Turing). Segundo o mesmo autor, o termo “agente” geralmente se refere a um
programa de software que reúne informações ou executa algum outro serviço sem a presença
imediata do usuário.
Fichter e Wisniewski (2017) sugerem que bots podem ser classificados em duas
categorias: (i) baseados em regras ou (ii) usar inteligência artificial (IA). Os baseados em regras
são mais limitados e não aprendem com as interações, enquanto que, aqueles baseados em IA
podem aprender e se tornar mais sofisticados. Algumas características dos bots são
apresentadas por Comarella e Café (2008, apud Franklin1)
•

Autonomia: Se refere ao controle que o agente tem sobre suas ações sem
interferência do ambiente ou mesmo de outros agentes;

1

http://www.msci.memphis.edu/~franklin/AgentProg.html - Este link está fora do ar entretanto a opção pelo
uso destas características foi mantida por ser um dos poucos trabalhos da CI que apresenta estas características.



•

Pró-atividade: Se refere à capacidade do agente para tomar iniciativas a fim de
atingir os objetivos;

•

Reatividade: Se refere à capacidade do agente em reagir às mudanças;

•

Continuidade temporal: Se observa que o agente está ativo indefinidamente;

•

Capacidade social: Se refere à capacidade que o agente tem de se comunicar
com outros agentes ou humanos;

•

Capacidade de adaptação: Se refere à capacidade do agente alterar seu
comportamento com base no que é observado no ambiente;

•

Mobilidade: Se refere a liberdade que o agente tem de atuar em um ambiente;

•

Caráter: Observa se o agente possui personalidade e estado emocional.

Para as autoras um agente não precisa possuir todas as características acima, mas pelo
menos, possuir uma delas.
4 BOTS x DESINFORMAÇÃO EM ELEIÇÕES
Baker (2015) relata o caso das eleições mexicanas de 2012 onde os “Penabots”, robôs
designados a auxiliar o candidato Peña Nieto, entravam em ação quando postagens negativas
sobre o candidato eram publicadas nas mídias sociais. Esses bots inundavam estas mesmas
mídias com notícias positivas a respeito do candidato minimizando o impacto das críticas.
Esta prática de “tecnocensura” (tecnocensoria) foi baseada em duas ações que são
conhecidas como “Social Spam” e “Data Flood”. Markines, Cattuti e Menczer (2009) apontam
que o “Social Spam” é a ação deliberada de espalhar conteúdo, de interesse ou não, em mídias
sociais de forma automatizada e com o maior alcance possível. De acordo com os autores, as
principais motivações para o uso do Social Spam é o baixo custo, rapidez de disseminação da
informação e a considerável capacidade de penetração nas massas. Kietzmann et al. (2011)
aponta que “Data Flood” ocorre nas mídias sociais quando a criação de conteúdo se dá em
quantidade massivas “afogando” os usuários em informações.
Neste caso a junção de “Social Spam” (disseminação da informação de forma automática
na rede) e “Data Flood” (grande volume de informações) se mostrou eficaz em abafar o impacto
das postagens negativas sobre o candidato e modificou, artificialmente, o sentimento sobre o
mesmo. Baker (2015) contou como um evento negativo com predomínio da hashtag #YoSoy132
(um protesto contra a parcialidade da mídia em relação a Peña) logo foi abafado pela hashtag



#PeñaGanaDebate (Relativo a um debate transmito em cadeia nacional) se transformando em
algo positivo a imagem de Peña.
Ferrara (2017) detalha outro caso ocorrido na eleição da França em 2017, se referindo
ao caso da coordenação de ataques cibernéticos, cuja a finalidade era revelar informações
sensíveis sobre o então candidato presidencial Emmanuel Macron, conhecido como o caso
Macronleaks. Como relata o autor, este caso apresentou dois ingredientes necessários a
desinformação: primeiro o de natureza não verificada da informação compartilhada, e o
segundo, o esforço coordenado por trás de sua partilha (social spam).
Neste caso, observa-se que o primeiro ingrediente que apresenta outros dois elementos,
nem tanto ligados aos bots, mas sim a desinformação, que são as notícias falsas (fake news) e a
pós-verdade. Reconhece Bezerra, Capurro e Schneider (2017) que as notícias falsas se referem
ao processo de criação e disseminação de conteúdo inverídico, enquanto que, a pós-verdade se
refere ao comportamento de colocar os fatos em segundo plano e tornar opiniões e préconceitos em um patamar de maior relevância.
Ferrara (2017) aponta que o impacto deste evento na França foi pequeno, porque a
maioria dos participantes do caso MacronLeaks não estava na comunidade francófona, mas sim
nos Estados Unidos. Estes mesmos bots foram utilizados nas eleições americanas, sugerindo a
existência de uma indústria da automação para disseminação das notícias falsas em eleições.
Lazer et al. (2018) analisa as eleições americanas e, dentre vários aspectos, aponta a existência
do fenômeno da utilização dos bots para enviar mensagens provocativas e até mesmo
depreciativas para outros usuários. Essas duas formas de expressão são conhecidas na Internet
como “Troll” e “Cyber-harassment”.
Shachaf e Hara (2010) afirma que o Troll, mais conhecido na linguagem cotidiana como
“trollagem”, se refere ao uso de mensagens em tom de agressão que aborreçam ou promovam
reações inflamadas dos receptores. A ideia por trás do Troll é trazer à tona reações não
conscientes, emocionais, dos receptores. Li (2005) coloca o “Cyber-harassment” como o assédio
que é dirigido a outros através do uso de informações e tecnologia de comunicação. Se difere
do “Cyber-Bullying” por não se estabelecer uma relação de poder, e sim, ser uma agressão
indesejada que afete a dignidade. Enquanto o “Bullying” tem um caráter mais pessoal (chefes,
colegas, parentes), o “Harassment” possui um caráter mais grupal (raça, cor, religião).
Lazer (2018) aponta que estes comentários foram usados na campanha de Donald
Trump, mas não comenta o impacto deles nos processos eleitorais como um todo. Entretanto,


observamos que isto é muito comum no Facebook de usuários brasileiros quando postam
notícias sobre política.
5 CONSIDERAÇÕES FINAIS
Esta pesquisa ainda está em andamento, os resultados relatados são preliminares, e
mesmo nos casos (eleições) citados, ainda há um conjunto de dados coletados a serem
analisados. Como um todo, busca-se observar como os bots foram utilizados para promover
ações comuns de mal comportamento na Internet, a partir da análise dos conceitos utilizados
no vocabulário específico do domínio (“Social Spam”, “Data Flood”, “Troll”, “Cyberharassment”, entre outros, tais como, “False advertising” e “Internet Bias”) e como cada um
deles ocorreu processos eleitorais. A ideia é reconher e classificar estes eventos em processos
eleitorais e enquadrá-los nas categorias de desinformação.
Além dos casos mencionados, já foram identificados casos de bots atuando em eleições
da EUA (2012), Itália (2012) Ucrania (2013), Brasil (2014), Equador (2014), México (2014), Russia
(2014), Turquia (2014), Venezuela (2014), Brexit (2016), China x Tibet (2016), e Brasil (2018 –
sim, já existem bots trabalhando nas eleições). A compreensão do uso dos bots nestas eleições
podem definir padrões sobre como desinformação ocorre, em escala global, nos processos
eleitorais.
Após discernir os fenômenos ocorridos em cada eleição, serão analisados os dados
quantitativos sobre a participação dos bots nas redes sociais e os resultados das eleições,
pesquisas intermediárias, notícias e comentários. E por fim, triangular os dados quantitativos e
qualitativos com tais fenômenos e identificar que ações dos bots estão ligadas a quais
consequências nas eleições.
