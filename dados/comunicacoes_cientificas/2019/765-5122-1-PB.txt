

COMPARA√á√ÉO ENTRE ALGORITMOS DE CLASSIFICA√á√ÉO APLICADOS NA PREDI√á√ÉO DE
NOT√çCIAS DE JORNAIS ON-LINE

Modalidade: Trabalho Completo
Resumo: Na internet existem informa√ß√µes imensur√°veis e muitas possibilidades ainda n√£o
exploradas, como por exemplo, os artigos de not√≠cias publicados no idioma portugu√™s. Assim, buscar
novos recursos, que sejam capazes de recuperar manchetes, de v√°rios portais, e disponibiliz√°-las em
classes, seria uma possibilidade muito eficiente e sofisticada para explorar informa√ß√µes. Deste modo,
esta pesquisa tem como objetivo comparar os resultados obtidos pelos algoritmos M√°quina de Vetor
de Suporte, √Årvore de Decis√£o, Regress√£o Log√≠stica, Floresta Aleat√≥ria, Naive Bayese AdaBoost na
classifica√ß√£o de not√≠cias, coletadas dos principais jornais on-line. Diferentes m√©todos s√£o empregados
para a classifica√ß√£o de textos, por√©m, podem apresentar desempenhos diferentes, sendo importante
test√°-los para verificar suas efic√°cias e assim, escolher o classificador que apresentar os melhores
resultados. Utilizou-se para treino uma amostra de 50 not√≠cias relacionadas a quatro assuntos
diferentes (biologia, economia, eletricidade e futebol) e para o teste um corpus contendo 10 not√≠cias.
Os corpora foram coletados no dia 17 de julho de 2019. As m√©tricas utilizadas para avaliar os
algoritmos foram a Acur√°cia, Precis√£o, Revoca√ß√£o, F1-score e a √Årea sob a Curva de Caracter√≠stica de
Opera√ß√£o do Receptor. Com base nos resultados das avalia√ß√µes, conclui-se que os classificadores
apresentaram excelentes resultados na predi√ß√£o desse tipo espec√≠fico de base textual, com exce√ß√£o
do algoritmo Naive Bayes que n√£o conseguiu alocar nenhuma not√≠cia na classe correta.
Palavras-Chave: Classifica√ß√£o de textos; Algoritmos; Medidas de avalia√ß√£o de sistemas de classifica√ß√£o.
1 INTRODU√á√ÉO
As not√≠cias de jornais on-line cont√™m uma enorme quantidade de dados em formato
n√£o estruturado que pode ser extra√≠da e transformada em informa√ß√µes valiosas de acordo
com a exig√™ncia do usu√°rio (LAMA, 2013). Essa massa de dados tem aumentado cada vez mais,
pois todos os dias, quintilh√µes de bytes de dados s√£o gerados provenientes do uso de m√≠dia
social e intera√ß√µes digitais (DAS, 2017). Essa quest√£o √© cada vez mais importante no mundo
dos neg√≥cios e da sociedade e fez com que a grande rede mundial de computadores se
tornasse um interessante objeto de estudo.
Na internet existem informa√ß√µes imensur√°veis e muitas possibilidades ainda n√£o
exploradas, como por exemplo, os artigos de not√≠cias publicados no idioma portugu√™s. Essas
publica√ß√µes s√£o fontes importantes de informa√ß√£o que mant√™m as pessoas atualizadas com
os acontecimentos atuais do mundo (LAMA, 2013). Por√©m, muitas vezes, a not√≠cia de um √∫nico
portal n√£o √© suficiente para obter todo o conhecimento desejado. Assim, √© necess√°rio recorrer
a v√°rios sites em busca de manchetes semelhantes, todavia, essa tarefa n√£o √© t√£o simples.
Segundo Liu (2007), os notici√°rios on-line geram diariamente uma grande quantidade de
informes e para fornecer um servi√ßo de not√≠cias integrado, os artigos coletados deveriam ser
dispostos em uma hierarquia de t√≥picos. Mas como essas not√≠cias podem ser organizadas?
Uma das possibilidades seria empregar um grupo de editores humanos para fazer o trabalho,

no entanto, a organiza√ß√£o manual √© dispendiosa e demorada, o que se torna inadequada para
not√≠cias e para outras informa√ß√µes que s√£o sens√≠veis ao tempo.
Assim, a classifica√ß√£o seria uma op√ß√£o para organizar artigos de not√≠cias de acordo com
categorias predefinidos. Por conseguinte, buscar novos recursos, que sejam capazes de
recuperar manchetes de v√°rios portais de not√≠cias, e disponibiliz√°-las em classes, seria uma
possibilidade muito eficiente e sofisticada para explorar informa√ß√µes. Por isso, a import√¢ncia
de um estudo na √°rea de classifica√ß√£o de textos, com o objetivo de desenvolver estrat√©gias
para classificar, automaticamente e de forma inteligente, informa√ß√µes importantes
recuperadas dos principais sites de not√≠cias e represent√°-las em classes, facilitando, deste
modo, o acesso aos informes atuais.
Com esse intuito, este trabalho tem como objetivo comparar os resultados obtidos
pelos algoritmos M√°quina de Vetor de Suporte, em ingl√™s Support Vector Machine (SVM),
√Årvore de Decis√£o, Regress√£o Log√≠stica, Floresta Aleat√≥ria, Naive Bayes e AdaBoost na
classifica√ß√£o de not√≠cias publicadas no idioma portugu√™s. Para a avalia√ß√£o do desempenho dos
classificadores foram usadas as m√©tricas Acur√°cia (Accuracy), Precis√£o (Precision), Revoca√ß√£o
(Recall), F1-score e √Årea sob a Curva Receiver Operating Characteristic (ROC).
Diversos m√©todos s√£o empregados para a classifica√ß√£o de textos, por√©m, podem
apresentar desempenhos diferentes, sendo importante test√°-los para verificar suas efic√°cias
e, desta forma, selecionar o classificador que apresentar os melhores resultados. Para isso,
foram utilizadas 60 amostras de not√≠cias relacionadas a quatro assuntos (futebol, economia,
eletricidade e biologia) coletadas em junho de 2019. Para testar os classificadores, foram
coletadas 10 not√≠cias usando para a busca a palavra-chave ‚ÄúCopa Am√©rica 2019‚Äù com o intuito
de verificar se o algoritmo seria capaz de predizer que essas not√≠cias pertencem √† classe
futebol.
Para melhor entendimento deste artigo, ser√£o conceituados alguns termos e
apresentados os principais algoritmos utilizados neste estudo.
2 CLASSIFICA√á√ÉO
O processo de inser√ß√£o dos documentos em classes √© comumente conhecido como
classifica√ß√£o de textos. ‚ÄúA classifica√ß√£o de textos prov√™ um meio para organizar a informa√ß√£o
que permite melhor compreens√£o e interpreta√ß√£o dos dados‚Äù (GON√áALVES, 2013, p.278).
Dessa forma, com a finalidade de aprimorar os recursos para organiza√ß√£o da informa√ß√£o,

estudos foram realizados e algoritmos foram desenvolvidos para a indu√ß√£o autom√°tica de
sistemas capazes de lidar com problemas de classifica√ß√£o. De acordo com Goldschmidt, Passos
e Bezerra (2015, p.89), a tarefa de classificar pode ser compreendida como ‚Äúa busca por uma
fun√ß√£o que permita associar corretamente cada registro Xi de um conjunto de dados a um
√∫nico r√≥tulo categ√≥rico Yi, denominado classe. Uma vez identificada, esta fun√ß√£o pode ser
aplicada a novos registros de forma a prever as classes em que tais registros se enquadram‚Äù.
A figura 1 ilustra as associa√ß√µes entre registros de dados e suas respectivas classes.
Figura 1: Associa√ß√µes entre registros de dados e classes

Conjunto de Dados

Conjunto de Classes

Fonte: Adaptada de Goldschmidt, Passos e Bezerra (2015, p.89)

Nesse contexto, Goldschmidt, Passos e Bezerra (2015, p.89) formalizaram a
classifica√ß√£o da seguinte forma:
Considere um conjunto de pares ordenados em que cada par √© da forma (x,
f(x)), onde x √© um vetor de entrada n-dimensional e f(x) a sa√≠da de uma
fun√ß√£o f, desconhecida, aplicada a x. A tarefa de classifica√ß√£o consiste em,
dada uma cole√ß√£o de exemplos de f, obter uma fun√ß√£o (hip√≥tese) h que seja
uma aproxima√ß√£o de f. A imagem de f √© formada por r√≥tulos de classes
retirados de um conjunto finito e toda hip√≥tese h chamada de Classificador.
O aprendizado consiste na busca pela hip√≥tese h que mais se aproxime da
fun√ß√£o original f. (GOLDSCHMIDT; PASSOS; BEZERRA, 2015, p.89).

De acordo com Gon√ßalves (2013, p.278), a classifica√ß√£o de textos prov√™ um meio de
organizar a informa√ß√£o que permite melhor compreens√£o e interpreta√ß√£o de dados. Em suma,
nesse processo, o algoritmo de aprendizado constr√≥i um classificador capaz de determinar
corretamente a classe de novos exemplos ainda n√£o etiquetados, dado um conjunto de classes
e um conjunto de exemplos de treinamento. Na maioria dos casos, a t√©cnica pode usar o
conhecimento de um dom√≠nio para fornecer alguma informa√ß√£o previamente conhecida como
entrada ao indutor. E, ap√≥s induzido, o classificador √© normalmente avaliado e a a√ß√£o de
classificar pode ser repetida, se necess√°rio (MONARD; BARANAUSKAS, 2003).


Assim, ‚Äúap√≥s a etapa de treinamento, tem-se um classificador que deve ser capaz de
predizer corretamente o r√≥tulo de novos exemplos, que ainda n√£o foram rotulados‚Äù
(REZENDE, 2005 apud BORGES, 2012, p.8). De acordo com Monard e Baranauskas (2003),
normalmente, um conjunto de exemplos √© dividido em dois subconjuntos: o conjunto de
treinamento √© utilizado para o aprendizado do conceito e o conjunto de testes usado para
medir o grau de efetividade do conceito aprendido. ‚ÄúEsses conjuntos s√£o normalmente
disjuntos para assegurar que as medidas obtidas, utilizando o conjunto de testes, sejam de
um conjunto diferente do usado para realizar o aprendizado, tornando a medida
estatisticamente v√°lida‚Äù (MONARD; BARANAUSKAS, 2003, p.97). O processo de classifica√ß√£o
de textos envolve as etapas de pr√©-processamento, extra√ß√£o de caracter√≠sticas, classifica√ß√£o
(predi√ß√£o) e a avalia√ß√£o dos resultados.
2.1 Pr√©-processamento e Normaliza√ß√£o dos dados
Antes de realizar a classifica√ß√£o, os documentos precisam ser processados e
normalizados. Isso envolve as seguintes fases:

a) Limpeza dos textos e Remo√ß√£o de caracteres especiais
As not√≠cias cont√™m conte√∫dos desnecess√°rios, como s√≠mbolos irrelevantes, caracteres
especiais, tags XML e HTML que n√£o agregam valor na an√°lise, portanto, eles devem ser
removidos. Outra importante tarefa na limpeza e normaliza√ß√£o de documentos √© remover
caracteres especiais como par√™nteses, colchetes e n√∫meros, pois eles aumentam o ru√≠do nos
textos. Express√µes regulares s√£o usadas nesse processo.

b) Stemming or lemmatization
Segundo Morais e Ambr√≥sio (2007), stemming √© uma t√©cnica de normaliza√ß√£o
lingu√≠stica, na qual as variantes de um termo s√£o reduzidas a uma forma comum denominada
stem (radical). Isso resulta na elimina√ß√£o de prefixos, sufixos e caracter√≠sticas de g√™nero,
n√∫mero e grau das palavras, reduzindo o n√∫mero de atributos. Na vis√£o de Monteiro e Gomes
et al. (2006), stemming consiste na remo√ß√£o de varia√ß√µes de palavras, tais como plural,
ger√∫ndio, afixos, g√™nero e n√∫mero, de modo que a palavra fique somente com a stem, ou seja,
com o radical. J√° o processo de lematiza√ß√£o √© muito parecido com o stemming, os afixos
5

XX ENCONTRO NACIONAL DE PESQUISA EM CI√äNCIA DA INFORMA√á√ÉO ‚Äì ENANCIB 2019
21 a 25 de outubro de 2019 ‚Äì Florian√≥polis ‚Äì SC
tamb√©m s√£o removidos, por√©m, obt√©m-se o lema da palavra e n√£o o radical. A diferen√ßa √© que
o radical nem sempre √© uma palavra lexicograficamente correta; isto √©, pode n√£o estar
presente no dicion√°rio. J√° o lema, sempre estar√° presente no dicion√°rio (SARKAR, 2019).

c) Remo√ß√£o das stopwords
Stopwords s√£o palavras irrelevantes e insignificantes que aparecem em uma linguagem
para ajudar a construir senten√ßas, mas que n√£o representam nenhum conte√∫do nos
documentos (LIU, 2007). S√£o palavras comuns, que repetem muitas vezes num texto e n√£o
acrescentam e nem retiram informa√ß√µes relevantes (SOLKA, 2007). Normalmente, s√£o artigos,
conjun√ß√µes e preposi√ß√µes que aparecem no corpus e que, apesar de ocorrerem com muita
frequ√™ncia em documentos, elas n√£o s√£o essenciais para dar sentido ao texto, pois s√£o usadas
apenas para juntar palavras em uma frase. Devido √† sua alta frequ√™ncia de ocorr√™ncia, sua
presen√ßa apresenta, muitas vezes, como um obst√°culo na an√°lise, por isso, a necessidade de
remov√™-las.
2.2 Extra√ß√£o de caracter√≠sticas
De acordo com Sarkar (2019), em aprendizado de m√°quina, as caracter√≠sticas ou
recursos s√£o propriedades ou atributos √∫nicos mensur√°veis de cada observa√ß√£o ou ponto de
dados em um dataset. Normalmente, recursos extra√≠dos s√£o usados pelos algoritmos de
Machine Learning para encontrar padr√µes de aprendizado que podem ser aplicados em novos
pontos de dados para obter insights. Esses algoritmos geralmente esperam caracter√≠sticas na
forma de vetores num√©ricos. Sendo assim, para a an√°lise das not√≠cias, os documentos
precisam ser transformados e representados em um formato num√©rico para que os algoritmos
de aprendizado de m√°quina possam compreender as informa√ß√µes contidas nos textos. Assim,
ao trabalhar com dados textuais, h√° o desafio adicional de descobrir como extrair recursos
num√©ricos a partir deles. Sarkar (2019) apresenta alguns modelos de extra√ß√£o de recursos em
documentos textuais, s√£o eles:

a)

Modelo Bag-of-Words
Normalmente, nesse modelo, o texto √© visualizado como uma sequ√™ncia de palavras e

√© dividido em tokens. Para isso, o conte√∫do de cada documento √© decomposto em termos e √©
verificada a frequ√™ncia de cada voc√°bulo no texto. Geralmente, o processo √© aplicado em um

conjunto de documentos e a cole√ß√£o √© transformada em uma matriz atributo-valor, na qual
cada linha representa um documento do conjunto, e cada documento √© descrito pelos valores
dos atributos mais representativos da cole√ß√£o (SOARES; PRATI; MONARD, 2009). O resultado
√© uma matriz de frequ√™ncia, que tamb√©m √© conhecida como Bag-of-Words (BoW), que √© a
representa√ß√£o num√©rica do corpus. Nesse modelo, a ordem e a sequ√™ncia de palavras n√£o s√£o
consideradas e ‚Äúos termos s√£o considerados independentes, formando um conjunto
desordenado em que a ordem de ocorr√™ncia das express√µes n√£o importa‚Äù (NOGUEIRA, 2009,
p.16). Em suma, o BoW √© um nome mais elegante para as matrizes de frequ√™ncia, √© uma forma
de representa√ß√£o de texto que computa a ocorr√™ncia dos termos em um documento.

b)

Modelo of N-Gramas
Um N-Gramas √© basicamente um conjunto de palavras de um documento de textos,

de modo que esses tokens s√£o cont√≠guos e ocorrem em uma sequ√™ncia. Desta forma, Bigramas indicam n-gramas de ordem 2 (duas palavras), tri-gramas indicam n-gramas de ordem
3 (tr√™s palavras) e assim por diante (SARKAR, 2019). Esse modelo √© apenas uma extens√£o do
BoW.

c)

Modelo Term Frequency ‚Äì Inverse Document Frequency
O Term Frequency Inverse Document Frequency (TF-IDF) √© uma medida estat√≠stica

usada para avaliar o qu√£o importante uma palavra √© para um documento em rela√ß√£o a uma
cole√ß√£o de documentos. Esse modelo √© a combina√ß√£o de duas m√©tricas: Term Frequency (TF)
e Inverse Document Frequency (IDF.). O TF mede com que frequ√™ncia um termo ocorre em um
documento e o IDF mensura o quanto um termo √© importante (LIU et al. 2007). Segundo
Baeza-Yates e Ribeiro-Neto (2013, p.35), a primeira forma de pondera√ß√£o da frequ√™ncia dos
termos foi proposta por Luhn em 1957, e baseia-se na seguinte suposi√ß√£o: ‚Äúo valor de peso de
um termo ki que ocorre em um documento dj √© simplesmente proporcional √† frequ√™ncia do
termo fi,j. Isto √©, quanto mais frequentemente um termo ki ocorrer no texto do documento dj
maior ser√° a sua frequ√™ncia de termo TFi,j‚Äù. De acordo com esses autores, essa hip√≥tese
baseia-se na observa√ß√£o que termos com alta frequ√™ncia s√£o importantes para descrever os
t√≥picos-chave de um documento. J√° o TF-IDF √© um c√°lculo que mostra o valor que cada palavra
tem em cada texto. A f√≥rmula para comput√°-lo √© a frequ√™ncia do termo num texto vezes o
inverso da frequ√™ncia desse voc√°bulo em todos os textos. Deste modo, ‚Äúuma palavra que
 NACIONAL DE PESQUISA EM CI√äNCIA DA INFORMA√á√ÉO ‚Äì ENANCIB 2019
21 a 25 de outubro de 2019 ‚Äì Florian√≥polis ‚Äì SC
aparece muitas vezes num texto n√£o ter√° tanto valor se aparecer igualmente muitas vezes nos
outros textos. Este m√©todo ajuda a distinguir palavras relevantes para o texto de palavras que
s√£o comuns‚Äù (RODRIGUES, 2016, p.21).
2.3 Algoritmos de classifica√ß√£o
Existem na literatura diversos algoritmos de aprendizado supervisionado para
classifica√ß√£o de textos. Segundo Gon√ßalves (2013), os algoritmos supervisionados de
classifica√ß√£o de textos mais representativos s√£o: √Årvore de decis√£o, Naive Bayes, SVM,
Floresta Aleat√≥ria, Regress√£o Log√≠stica e AdaBoost. Abaixo, uma descri√ß√£o dos principais
m√©todos existentes.

a)

√Årvore de decis√£o
Para Faceli et. al (2017, p.83), ‚Äúuma √°rvore de decis√£o usa a estrat√©gia de dividir para

conquistar para resolver um problema de decis√£o‚Äù. Um classificador de texto desse tipo √© uma
√°rvore em que os n√≥s internos s√£o rotulados pelos termos, os ramos que partem dos n√≥s s√£o
definidos pelos testes, levando-se em considera√ß√£o o peso que o termo tem no teste do
documento e as folhas pelas categorias. Segundo Prates (2018), √© uma ferramenta de suporte
a tomada de decis√£o que usa um gr√°fico no formato de √°rvore e demonstra visualmente as
condi√ß√µes e as probabilidades para se chegar a resultados. A Figura 3 ilustra uma √°rvore de
decis√£o, ou seja, um modo de representar o conhecimento.
Figura 2: Exemplo de √°rvore de decis√£o

Fonte: Lobo (2010, p.2)


b)

M√°quinas de Vetores de Suporte
SVM √© um conjunto de m√©todos de aprendizado supervisionado utilizados tanto para

classifica√ß√£o quanto para regress√£o. Segundo Ticom (2007), √© um dos mais populares
classificadores do tipo linear. Ela implementa a ideia de que seja constru√≠do um hiperplano
com base no mapeamento dos vetores de entrada em um espa√ßo de caracter√≠sticas com uma
grande quantidade de dimens√µes. Quando os dados do arquivo de treino s√£o separ√°veis, a
taxa de erro para o SVM pode ser definida pela equa√ß√£o (TICOM, 2007, p.29): h = R2 / M2, no
qual R √© o raio da menor esfera que cont√©m os dados de treinamento e M √© a margem que
significa a dist√¢ncia entre o hiperplano e o vetor de treino mais perto do espa√ßo de
caracter√≠sticas.

c)

Random Forest
A Floresta Aleat√≥ria √© uma t√©cnica que permite obter modelos muito eficazes sem

nenhuma prepara√ß√£o de dados ou conhecimento de modelagem (BREIMAN; CUTLER, 2014).
Como o nome j√° diz, o algoritmo cria uma floresta de um modo aleat√≥rio. De acordo com Han
Kamber e Pei (2012), uma Random Forest pode ser descrita como um classificador formado
por um conjunto de √°rvores de decis√£o {h (X, vk), k, 1, ..}, no qual vk s√£o vetores aleat√≥rios
amostrados de forma independentes, distribu√≠dos igualmente em todas as √°rvores da floresta.
O resultado do processo de classifica√ß√£o √© a classe X com maior n√∫mero de votos dentre todas
as √°rvores consideradas.

d)

Naive Bayes
√â um m√©todo probabil√≠stico, no qual se assume que todas as vari√°veis s√£o

independentes da vari√°vel de classifica√ß√£o, o que o torna muito f√°cil para criar uma rede
estruturada e n√£o obriga a gera√ß√£o de um algoritmo de aprendizado. Este classificador se
baseia no teorema de Bayes com a simplifica√ß√£o de que, ap√≥s o treinamento, pode ser
assumido que as caracter√≠sticas s√£o independentes para uma dada classe (TICOM, 2007, p.28).
Em reconhecimento de padr√µes ou classifica√ß√£o, interessa-se em associar a um padr√£o
uma classe. Assim, sejam padr√µes x = (x1, x2, ... , xd) ‚àà‚Ñùd e classes {œâ1, œâ2, ... , œâc}, a abordagem
Bayesiana sup√µe que as probabilidades de cada classe P(œâi) e as densidades de probabilidade
condicionais p(x|œâi) de x com respeito a cada uma das classes œâi,i = 1, 2, ... , c, s√£o conhecidas.
Na aus√™ncia de qualquer outra informa√ß√£o, pode-se classificar um padr√£o x como sendo da

classe œâi de maior probabilidade. Entretanto, dado que x foi observado, isto parece uma
decis√£o muito ing√™nua, pois acertaria a classifica√ß√£o com probabilidade P(œâi), por√©m erraria
com probabilidade ‚àëùëó ‚â†ùëñ ùëÉ(ùúîùëó ). Como tem as condicionais, pode-se utilizar o teorema de
Bayes e calcular a probabilidade P(œâi |x), ou seja, P(œâi|x) =

ùë∑(ùùéùíä )ùê©(ùê±|ùùéùíä )
ùíë(ùê±)

na qual P(œâi) √© a priori,

p(x|œâi) √© a densidade condicional ou verossimilhan√ßa, p(x) = ‚àëùëêùëó=ùëñ ùëÉ(ùúîùëó)ùëù(ùë•|ùúîùëó) √© a evid√™ncia
e P(œâi|x) √© a posteriori, e tomar a decis√£o baseada nesses a posteriores (HIRATA, 2007).

e)

Regress√£o Log√≠stica
Segundo Nisbet, Elder e Miner (2009), a regress√£o log√≠stica √© utilizada para modelar a

rela√ß√£o n√£o linear de uma vari√°vel dependente e os efeitos combinados de vari√°veis
independentes. Para esses autores, essa rela√ß√£o representa a probabilidade de ocorr√™ncia de
um evento. Diferente de uma regress√£o linear simples, os valores observados para a vari√°vel
dependente, quando colocados num plano cartesiano, n√£o formam uma nuvem de pontos,
mas ficam restritos a zero e a 1. Deste modo, o que se faz com a regress√£o log√≠stica √© atribuir
escores calculados a partir das vari√°veis independentes, a fim de que, quando a vari√°vel
dependente pertencer ao grupo zero, ela tenha um baixo escore, enquanto os escores
associados √†s vari√°veis dependentes do grupo 1 devem ser mais altos (SOARES; REBOU√áAS,
2015).

f)

Adaboost
Segundo Nascimento (2011), o Adaboost √© um algoritmo de aprendizado

supervisionado do tipo boost que combina um conjunto de fun√ß√µes simples de classifica√ß√£o,
denominadas classificadores fracos, para formar um classificador forte. Para a autora, um
classificador fraco √© uma estrutura simples que cont√©m um vetor de caracter√≠sticas f, um limiar
e uma paridade. Durante o treinamento do classificador fraco deve ser encontrado um limiar
que melhor separe o valor de uma caracter√≠stica de exemplos definidos como positivos dos
negativos.

2.4 Avalia√ß√£o dos modelos de classifica√ß√£o
Segundo Sarkar (2019), o desempenho dos modelos de classifica√ß√£o geralmente √©
baseado em qu√£o bem eles preveem resultados para novos pontos de dados. Assim, os

documentos s√£o classificados a partir de caracter√≠sticas do texto, como termos ou palavras
presentes nas not√≠cias. Baseia-se na an√°lise pr√©via de um conjunto de amostragem ou de
treinamento, contendo objetos corretamente classificados. E o desempenho, normalmente,
√© medido em rela√ß√£o a um conjunto de teste que consiste em elementos que n√£o foram
usados para influenciar ou treinar o classificador. Assim sendo, na avalia√ß√£o, √© necess√°rio
escolher m√©tricas corretas que possam pontuar qual √© o melhor modelo de classifica√ß√£o. Para
isso, recursos s√£o extra√≠dos ao treinar o modelo. As informa√ß√µes obtidas pela amostra j√°
treinada s√£o usadas para fazer previs√µes de novos textos ainda n√£o etiquetados. Essas
previs√µes s√£o ent√£o combinadas com os r√≥tulos reais para ver o quanto o modelo previu.
V√°rias m√©tricas determinam o desempenho de previs√£o de um modelo, mas este estudo
concentrou nas seguintes medidas: Acur√°cia, Precis√£o, Revoca√ß√£o, F1-score e √Årea sob a Curva
ROC.

a) Acur√°cia
Segundo Baeza-Yates e Ribeiro-Neto (2013) acur√°cia √© a fra√ß√£o dos documentos de
treinamento atribu√≠dos a suas classes corretas pelo classificador. Medidas acuradas ou exatas
s√£o aquelas cujo valor m√©dio se aproxima do valor correto. Sarkar (2019) define acur√°cia como
a exatid√£o geral ou a propor√ß√£o de previs√µes corretas do modelo.

b) Precis√£o
Baeza-Yates e Ribeiro-Neto (2013) conceituam precis√£o como a fra√ß√£o de documentos
relevantes do total recuperados. Segundo Sarkar (2019), precis√£o √© definida como o n√∫mero
de progn√≥sticos feitos que s√£o realmente corretos ou relevantes de todas as previs√µes
baseadas na classe positiva. A capacidade de precis√£o, ou relev√¢ncia, est√° relacionada ao
n√∫mero de documentos recuperados para atendimento das solicita√ß√µes encaminhadas pelo
usu√°rio. Tamb√©m pode ser mensurada por meio da rela√ß√£o entre os documentos relevantes
recuperados e n√∫mero total de documentos recuperados (FUJITA, 2009).

c) Revoca√ß√£o
Baeza-Yates e Ribeiro-Neto (2013) definem revoca√ß√£o como a fra√ß√£o dos documentos
relevantes recuperados. A capacidade de revoca√ß√£o diz respeito ao n√∫mero de documentos
recuperados e pode ser mensurada por meio da rela√ß√£o entre o n√∫mero de documentos

relevantes sobre determinado tema, recuperados pelo sistema de busca, e o n√∫mero total de
documentos sobre o assunto, existentes nos registros do mesmo sistema (FUJITA, 2009). Para
Sarkar (2019), revoca√ß√£o pode ser definida como o n√∫mero de inst√¢ncias da classe positiva
que foram corretamente preditas.

d) F1-score
A pontua√ß√£o F1 √© outra medida de precis√£o que √© calculada tomando a m√©dia
harm√¥nica da precis√£o e da revoca√ß√£o (SARKAR, 2019). Sendo assim, quando se tem F1-Score
baixo, √© um indicativo de que ou a precis√£o ou a revoca√ß√£o est√° baixa.

e) √Årea sob a Curva ROC
Segundo Prati, Batista e Monard (2008), a an√°lise ROC √© um m√©todo gr√°fico para
avalia√ß√£o, organiza√ß√£o e sele√ß√£o de sistemas de diagn√≥stico e/ou predi√ß√£o. Essa t√©cnica foi
introduzida em Aprendizagem de M√°quina e Minera√ß√£o de Dados como uma ferramenta √∫til
e poderosa para a avalia√ß√£o de modelos de classifica√ß√£o. Ela √© particularmente √∫til em
dom√≠nios nos quais existe uma grande despropor√ß√£o entre as classes ou quando se deve levar
em considera√ß√£o diferentes custos/benef√≠cios para os diferentes erros/acertos de
classifica√ß√£o.
3 METODOLOGIA
Para a realiza√ß√£o desta pesquisa de natureza quali-qualitativa e de car√°ter
experimental, o primeiro passo foi coletar os informes dos principais jornais on-line. Para isso,
utilizou-se o Mediaframe1. O MediaFrame √© um projeto da Funda√ß√£o Get√∫lio Vargas que
permite pesquisar e capturar um grande n√∫mero de not√≠cias dos principais jornais on-line.
Como √© um sistema de acesso restrito, uma outra op√ß√£o para a coleta dos dados seria o
desenvolvimento de um web crawler que fosse capaz de rastrear a internet e extrair de forma
automatizada as informa√ß√µes desejadas, pois a captura manual seria dispendiosa e demorada.
Para a realiza√ß√£o deste trabalho, recuperaram-se dois conjuntos de not√≠cias, um
utilizado para treino e o outro para teste. E para o processamento dos textos, usou-se o
Orange Canvas2, um software open source que al√©m de an√°lise e visualiza√ß√£o de dados, possui
1
2

https://mediaframe.io
https://orange.biolab.si/

um m√≥dulo para text mining. Assim, pode-se utilizar os algoritmos de Data Mining e Text
Mining com programa√ß√£o visual (widgets) que j√° vem incorporado no programa, al√©m da
possibilidade de incrementar novas funcionalidades atrav√©s de scripts em Python.
O experimento foi feito da seguinte forma: a base total √© composta por 60 documentos
que foram separados aleatoriamente em bases menores formando o corpus com 13 not√≠cias
relacionadas a futebol, 12 sobre biologia, 12 sobre eletricidade e 13 relacionadas √† economia,
formando uma amostra de 50 not√≠cias que foram usadas para o treino. Para a realiza√ß√£o dos
testes, foram usadas 10 mat√©rias relacionadas ao tema futebol. Para melhor entendimento,
ser√° explanado separadamente as duas fases do processo de classifica√ß√£o: Treino e Teste.
3.1 Treino do modelo
Na fase de aprendizado, o sistema aprende e constr√≥i uma base de conhecimento a
partir de um conjunto de amostras que lhe s√£o fornecidos. A figura 4 apresenta o fluxograma
da metodologia proposta para a fase de treino na classifica√ß√£o de not√≠cias disseminadas pelos
meios de comunica√ß√£o em massa:
Figura 3: Fluxograma da metodologia na fase de treino
Etapa IV

Etapa V
Etapa II

Etapa III

Etapa I

Fonte: elaborado pelos autores usando o software Orange Canvas

As etapas da fase de treinamento, ilustradas no fluxograma, ser√£o descritas para
melhor entendimento.
3.1.1 Constru√ß√£o do Corpus de not√≠cias para treinamento
Esta etapa tem como objetivo coletar, dos principais sites de not√≠cias, uma amostra de
documentos para a realiza√ß√£o da an√°lise. Para isso, utilizou-se o Mediaframe. Primeiramente,
define-se a palavra-chave usada na consulta. Em seguida, escolhem-se os principais jornais
para a busca e determina-se o per√≠odo desejado em que as not√≠cias foram publicadas.
Posteriormente, o Mediaframe rastreia cada uma das fontes para descobrir os
informes relacionados ao assunto pesquisado. Depois, o sistema permite fazer o download do
conjunto de not√≠cias recuperado em formato csv. Sendo assim, primeiro, coletou-se a amostra
para o treinamento, a cole√ß√£o foi formada por quatro classes diferentes (economia, futebol,
eletricidade e biologia). Cada mat√©ria cont√©m as seguintes informa√ß√µes: id, website, data da
publica√ß√£o, t√≠tulo e o texto. Por√©m, neste trabalho, foram selecionadas somente as colunas
do t√≠tulo e do conte√∫do da not√≠cia. Em seguida, os corpora foram concatenados formando um
√∫nico corpus contendo as quatro classes.
3.1.2 Pr√©-processamento das not√≠cias
Devido √† natureza textual n√£o estruturada, os documentos necessitam de um pr√©processamento para serem submetidos a algoritmos de aprendizagem. A transforma√ß√£o dos
documentos em uma representa√ß√£o mais adequada √© uma etapa de suma import√¢ncia, visto
que a representa√ß√£o desses documentos tem uma influ√™ncia fundamental em qu√£o bem um
algoritmo de aprendizado poder√° generalizar a partir dos exemplos (SEBASTIANI, 2002).
Diante disso, os conte√∫dos das not√≠cias, acompanhados de seus t√≠tulos, s√£o
processados usando t√©cnicas de pr√©-processamento de documentos. Esse processo inclui as
seguintes etapas:
a) Limpeza
Nesta etapa o texto foi convertido para min√∫sculo, acentos, tags HTML e URL foram
removidos. Al√©m disso, usaram-se express√µes regulares para eliminar caracteres especiais e
n√∫meros.
b)

Tokeniza√ß√£o
A tokeniza√ß√£o ou tokenization √© uma etapa importante para o pr√©-processamento.

Nesta fase, as not√≠cias recuperadas pelo Mediaframe s√£o submetidas a in√∫meras opera√ß√µes
para serem representadas estruturalmente, pois antes de realizar qualquer an√°lise, √©
necess√°rio normalizar os documentos de texto.
Para isso, primeiramente, ser√£o identificadas nas amostras de not√≠cias as palavras mais
importantes, isto √©, que melhor representam as ideias dos textos. Esse processo de
identifica√ß√£o das palavras √© conhecido como tokenization. O procedimento divide uma
unidade de documento em peda√ßos, denominados tokens.

c)

Remo√ß√£o das stopwords
Nesta etapa, realizou-se a elimina√ß√£o das stopwords, que s√£o palavras que t√™m pouca

ou nenhuma signific√¢ncia. Assim, os artigos, os pronomes, as preposi√ß√µes e as interjei√ß√µes s√£o
consideradas stopwords. Elas geralmente s√£o removidas do texto durante o processamento,
de modo a reter os termos mais relevantes. Como n√£o existe uma lista universal de stopwords,
cada dom√≠nio ou idioma pode ter seu pr√≥prio conjunto. Neste trabalho, foram adotadas
stopwords para o idioma Portugu√™s. Al√©m disso, para reduzir os termos de pouca relev√¢ncia
nos textos, a lista foi cuidadosamente atualizada com outros voc√°bulos, tais como verbos
gen√©ricos ou substantivos sem muita import√¢ncia, que foram cuidadosamente selecionados
depois de analisar o corpus.
Portanto, a fase de remo√ß√£o das stopwords √© importante para reduzir o n√∫mero de
palavras envolvidas nos processos posteriores de an√°lise, de modo a conseguir um melhor
desempenho sem perda significativa de informa√ß√£o √∫til.
d)

Stemming
O passo seguinte √© identificar e unificar termos que possuam o mesmo significado

sem√¢ntico. Muitas vezes, prefixos e sufixos s√£o anexados a um tronco de palavras para mudar
seu significado ou criar uma nova express√£o. O objetivo desta etapa √© remover esses afixos e
retornar as palavras em sua forma b√°sica, ou seja, reduzir o termo a sua raiz.


3.1.3 Representa√ß√£o do Modelo de documentos
Uma importante etapa no processo de classifica√ß√£o √© representar o conte√∫do do
documento sob a forma de express√£o matem√°tica para posterior an√°lise e processamento. A
representa√ß√£o de textos pode ser feita usando diversas abordagens, entre elas, a BoW.
Portanto, nesta etapa, com o corpo de not√≠cias normalizado, uma matriz de caracter√≠stica √©
constru√≠da. Para isso, os tokens dos textos s√£o mantidos nos documentos normalizados e as
caracter√≠sticas s√£o extra√≠das, com base no modelo TF-IDF, de modo que cada caracter√≠stica
ocorra em pelo menos 25% dos documentos e no m√°ximo 85% dos documentos. Para
controlar a porcentagem, s√£o usadas as frequ√™ncias m√≠nima e m√°xima dos termos no
documento.
3.1.4 Escolha dos algoritmos de classifica√ß√£o
Nesta pesquisa foi avaliado o desempenho dos algoritmos SVM, √Årvore de Decis√£o,
Regress√£o Log√≠stica, Floresta Aleat√≥ria, Naive Bayes e AdaBoost.

3.1.5 Avalia√ß√£o dos algoritmos de classifica√ß√£o
Existem diversas maneiras de se avaliar o processo de classifica√ß√£o como um todo, seja
de forma qualitativa ou quantitativa. A utiliza√ß√£o de m√©tricas √© considerada uma forma
quantitativa, ao passo que a utiliza√ß√£o do conhecimento de especialistas no dom√≠nio √©
considerada uma forma qualitativa. Para a avalia√ß√£o dos algoritmos de classifica√ß√£o,
utilizaram-se as m√©tricas de Precis√£o, Acur√°cia, Revoca√ß√£o, F1-score e √Årea sob a Curva ROC.
3.2 Teste do modelo
Na etapa de teste, o modelo utiliza o conhecimento adquirido na fase de treino para
classificar os documentos cujas classes s√£o desconhecidas.
A figura 5 apresenta o fluxograma da metodologia proposta ap√≥s acr√©scimo da fase de
teste na classifica√ß√£o de not√≠cias coletadas dos principais jornais on-line. Neste experimento,
realizou-se o teste com uma cole√ß√£o de 10 not√≠cias relacionadas ao tema futebol.


Figura 4: Fluxograma da metodologia incluindo a fase de teste

Teste
Fonte: Elaborada pelos autores usando o software Orange Canvas

As fases necess√°rias para testar os algoritmos s√£o descritas abaixo:
3.2.1 Constru√ß√£o do Corpus de not√≠cias para teste
Nesta etapa, coletaram-se 10 not√≠cias usando na busca a palavra-chave ‚ÄúCopa Am√©rica
2019‚Äù, assunto relacionado com a classe futebol. De posse do corpus, os textos passaram por
todas as etapas do pr√©-processamento (limpeza, tokeniza√ß√£o, remo√ß√£o das stopwords e
stemming) conforme realizado na cole√ß√£o de treino. Em seguida, as not√≠cias foram
representadas no modelo BoW.
3.2.2 Predi√ß√£o
Neste passo, o classificador usa a base de conhecimento adquirida na fase de
treinamento para classificar cada item da cole√ß√£o de teste.
3.2.3 An√°lise e valida√ß√£o dos resultados
Esta etapa tem como objetivo verificar se o algoritmo foi capaz de predizer se as
not√≠cias utilizadas na fase de teste pertencem √† classe futebol.



4 AN√ÅLISE DOS RESULTADOS
Para avaliar o desempenho de t√©cnicas de classifica√ß√£o aplicadas a corpus de not√≠cias,
construiu-se um modelo de classifica√ß√£o para testar cinco algoritmos: SVM, √Årvore de Decis√£o,
Regress√£o Log√≠stica, Floresta Aleat√≥ria, Naive Bayes e AdaBoost. A tabela 1 mostra os valores
de acertos dos algoritmos ao serem submetidos √† an√°lise de curvas ROC e avaliados usando
as m√©tricas de Precis√£o, Acur√°cia, Revoca√ß√£o e F1-score.
Tabela 1: Avalia√ß√£o dos algoritmos de classifica√ß√£o
M√©todo
Decision Tree
SVM
Random Florest
Naive Bayes
Logist Regression
AdaBoost

AUC
Accuracy
F1-score
0.818
0.842
0.770
0.664
0.460
0.446
0.953
0.932
0.916
0.562
0.250
0.208
0.983
0.957
0.954
0.954
0.979
0.979
Fonte: Elaborada pelos autores

Precision
0.709
0.446
0.934
0.261
0.959
0.980

Recall
0.842
0.460
0.932
0.250
0.957
0.979

Observa-se que os algoritmos Floresta Aleat√≥ria, Regress√£o Log√≠stica e AdaBoost
apresentaram um melhor desempenho. O classificador Naive Bayes e a SVM tiveram os piores
resultados. Nota-se tamb√©m que muitos dos algoritmos mostraram desempenhos
satisfat√≥rios para o problema de classifica√ß√£o de not√≠cias, pois obtiveram precis√£o e acur√°cia
superior a 0.9. Em contrapartida, Naive Bayes obteve um valor baixo em todas as m√©tricas,
portanto, n√£o √© indicado para esse tipo de textos. Por√©m se faz necess√°rio novos
experimentos com novas cole√ß√µes, aumentando e reduzindo a quantidade de documentos
para, assim, analisar se o desempenho dos algoritmos continua semelhante com outros
corpora.
Ao efetuar o teste usando um corpus sem r√≥tulo, os algoritmos apresentaram alta taxa
de acerto, a Figura 6 ilustra o resultado.
Figura 5: Resultado da predi√ß√£o

Fonte: Elaborada pelos autores usando o software Orange Canvas

Para melhor compreens√£o da Figura 6, elaborou-se um quadro com as legendas das
classes.
Quadro 1: Legenda da Figura 11
Classe (0)
Classe (1)
Classe (2)
Classe (3)

LEGENDA
Biologia
Futebol
Eletricidade
Economia
Fonte: Elaborada pelos autores

Percebe-se na Figura 6 que os algoritmos √Årvore de Decis√£o, Floresta Aleat√≥ria,
AdaBoost e SVM acertaram 100% ao classificar todas as not√≠cias como pertencente √† classe
(1), ou seja, futebol. J√° o algoritmo Naive Bayes errou 100%, pois classificou toda a cole√ß√£o de
not√≠cias como pertencente √† classe (3), isto √©, economia. Logo, a maioria dos algoritmos
conseguiram um excelente desempenho na classifica√ß√£o de um corpus pequeno de not√≠cias.
5 CONSIDERA√á√ïES FINAIS
A classifica√ß√£o de textos √© uma das mais importantes aplica√ß√µes do processamento de
linguagem natural e tem grande utilidade quando se deseja organizar documentos. Os
resultados desta pesquisa mostram que os classificadores tiveram boa performance na
classifica√ß√£o de not√≠cias. E, se comparado com a classifica√ß√£o manual, o ganho de tempo √©
muito grande. Por√©m, o desempenho √© significativo quando se trabalha com um n√∫mero
pequeno de termos, por isso, a import√¢ncia do pr√©-processamento, pois essa etapa consegue
um ganho significativo da redu√ß√£o da dimensionalidade dos textos. Isso faz com que os
algoritmos de aprendizagem de m√°quina aprimorem a precis√£o da classifica√ß√£o al√©m de
reduzir o custo computacional.
Ao analisar os resultados das valida√ß√µes, levando-se em conta a Acur√°cia, Precis√£o,
Revoca√ß√£o e a An√°lise da Curva ROC de cada algoritmo, conclui-se que os programas mais
indicados para este tipo de base textual, que no caso deste experimento s√£o as not√≠cias, s√£o
a √Årvore de Decis√£o, Floresta Aleat√≥ria, M√°quina de Vetor de Suporte e o AdaBoost que, nesse
caso, conseguiram 100% de acertos. J√° o algoritmo Naives Bayes apresentou resultado
insatisfat√≥rio na predi√ß√£o e √© invi√°vel para este tipo espec√≠fico de base textual.


Por conseguinte, com base nos resultados deste experimento, √© poss√≠vel afirmar que
esses modelos constituem uma ferramenta poderosa na classifica√ß√£o de textos, podendo
auxiliar leitores e organizadores da informa√ß√£o.
Como trabalhos futuros, seria interessante analisar o desempenho dos classificadores
com v√°rios corpora para verificar com mais precis√£o se a quantidade de documentos e a
natureza das not√≠cias influenciam no desempenho dos algoritmos.
