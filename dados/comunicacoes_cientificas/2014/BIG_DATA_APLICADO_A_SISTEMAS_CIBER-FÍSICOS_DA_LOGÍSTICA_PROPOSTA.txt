

BIG DATA APLICADO A SISTEMAS CIBER-FÍSICOS DA LOGÍSTICA: PROPOSTA
DE MODELO CONCEITUAL
Resumo: Os Sistemas Ciber-físicos combinam aspectos cibernéticos da computação e
comunicação com a dinâmica dos sistemas físicos operados no mundo real. Juntamente com a
grande relevância do gerenciamento e análise das informações com vistas ao planejamento e
controle dos sistemas logísticos, considera-se que utilização de técnicas e tecnologias de Big
Data e Business Analytics possa impulsionar a tomada de decisão dentro destes sistemas.
Neste sentido, o processo de tomada de decisão é estratégico para se lidar com enormes
quantidades de dados, analisar a informação e determinar como se trabalhar com tal volume e
variedade de informações na velocidade adequada. Este trabalho é uma pesquisa aplicada, que
propõe um modelo conceitual para combinar práticas de gestão com a aplicação de técnicas
inovadoras para aquisição e análise de dados nos Sistemas Ciber-físicos. Ao final, conclui-se
que as organizações não irão colher os benefícios de uma transição para o uso de Big Data, a
não ser que sejam capazes de gerenciar efetivamente este processo de mudança.
Palavras-chave: Big Data. Business Analytics. Sistemas Ciber-físicos. Logística.
1 INTRODUÇÃO
Considera-se a Logística uma parte da gestão da cadeia de suprimentos que se ocupa
da movimentação de produtos desde a emissão do pedido até a distribuição, por meio de
estágios, tais como aquisição de matéria prima, produção, movimentações internas e externas

139
140
141

UFSC.
UFSC.
UFSC.



de suprimentos e de distribuição sendo que, neste contexto, destaca-se como ponto crítico o
gerenciamento das informações relativas a este processo (DUTRA et al., 2013).
A competitividade de uma cadeia de suprimentos depende cada vez mais da sua
flexibilidade. As melhores não são apenas rápidas e eficientes, mas igualmente ágeis e
autoadaptáveis (LEE, 2004). Por exemplo, períodos de desenvolvimento mais curtos,
produção de bens variáveis e individualmente configuráveis são estratégias apropriadas para
satisfazer o consumidor e responder tão rápido quanto possível às mudanças de demanda
existentes (RICHTER, 2007). Logo, a logística precisa compensar os requisitos crescentes da
flexibilidade por meio da utilização de uma maior densidade da informação e do emprego de
técnicas inovadoras para a aquisição e análise de dados. Consequentemente, o fluxo da
informação que comanda todo este processo representa uma questão crítica a ser abordada, e
tem propulsionado uma grande quantidade de investimentos em tecnologias de apoio
(BANDEIRA; MAÇADA, 2008; LASETER; OLIVER, 2005), tais como as tecnologias e
técnicas de Big Data.
Este estudo faz parte de um projeto de pesquisa em andamento que envolve a Ciência
da Informação e a Engenharia de Produção. Nele, buscou-se apresentar uma proposta de
modelo conceitual que utilize as técnicas de Big Data aplicadas dentro de um contexto de
Sistemas Ciber-físicos da Logística.
2 SISTEMAS CIBER-FÍSICOS
O conceito de um sistema que una funções físicas e perspectivas relacionadas à
informação vem sido bastante trabalhado ultimamente (BROY, 2010). As capacidades dos
assim chamados Sistemas Ciber-físicos (SCF) permitem a divisão do sistema em diversas
entidades capazes de se comunicar, de reconhecer seu ambiente e de tomar decisões. Um SCF
acumula os benefícios advindos dos sistemas embarcados com a possibilidade de comunicarse numa variedade grande de tecnologias de comunicação. Além disso, eles permitem a
conexão entre o fluxo informacional e o fluxo de material nos processos logísticos
(HRIBERNIK et al., 2010).
A combinação de objetos físicos com inteligência cibernética, trazida pela aplicação
dos SCF, cria um novo potencial para eficiência melhorada, accountability (capacidade para a
prestação de contas), sustentabilidade e escalabilidade nos sistemas logísticos. De fato, esta
combinação é considerada por muitos pesquisadores e usuários como uma das grandes
tendências e um dos maiores desafios da indústria no futuro. Com respeito a esta integração, é
primordial que uma boa gestão de informação seja a viga mestre para o desenvolvimento de



sistemas de apoio à decisão apropriados (DUTRA et al., 2013). O conhecimento deste
contexto é um dos fundamentos dos sistemas ciber-físicos. É possível agregar informação de
sistemas distribuídos de dados relacionados à logística por meio da combinação de padrões e
sistemas já existentes. Através da agregação dos SCF com as redes de comunicação, é
fomentada a interação entre o mundo físico e o mundo cibernético (HANS et al., 2008).
3 BIG DATA E BUSINESS ANALYTICS
De acordo com Krishnan (2013), Big Data consiste de uma vasta quantidade de dados
disponíveis em diferentes níveis de complexidade – criados por humanos ou por máquinas em
diferentes ritmos –, e que apresentam grandes níveis de ambiguidade, de forma que não
podem ser processados computacionalmente por meio da utilização de tecnologias,
dispositivos de comunicação, métodos de processamento e algoritmos tradicionais, além de
qualquer outra solução similar. Segundo Katal et al. (2013), Big Data se refere a grandes
quantidades de dados que necessitam de novas tecnologias e arquiteturas para efetuar a
recuperação da informação, que deve ser feita através de processos específicos de coleta e
análise.
Business Analytics (BA) é um conceito definido como a aplicação de várias técnicas
avançadas de análise de dados, de maneira a responder determinadas indagações ou resolver
problemas numa determinada área do conhecimento (DAVENPORT, 2009). Esta definição se
refere ao uso de modelos quantitativos e preditivos e de apoio baseado em fatos para o suporte
à decisão. O significado de BA abrange mineração de dados, análise preditiva, estatística e
análise aplicada. Desta forma, pode-se ver que o conceito de BA possui muitas similaridades
com o conceito de Big Data, pois ambos procuram recuperar informações a partir de dados.
Ward e Barker (2013) relatam que, depois de analisarem diversas definições de Big
Data, chegaram à conclusão de que todas fazem alusão a três importantes aspectos: (i)
tamanho: o volume de dados é um fator crítico; (ii) complexidade: a estrutura, seu
comportamento e as permutas feitas entre os datasets também são um fator crítico; e (iii)
tecnologia: as ferramentas e técnicas usadas para processas os datasets são essenciais.
No entanto, em consonância com a análise acima, três aspectos diferenciam Big Data
de BA: volume, velocidade e variedade. O seja, os dados do Big Data, juntamente com a
tecnologia necessária para coletá-los e processá-los, diferem do BA pelos enormes valores
nesses três aspectos. Além disso, em alguns casos, a velocidade da criação de dados é até mais
importante do que o volume dos mesmos, por exemplo, informação em tempo-real, ou em
tempo-quase-real, pode ser decisiva para o sucesso ou fracasso de sistemas que operem nesta


velocidade (WARD; BARKER, 2013). Com relação às características do conteúdo existente
no Big Data, pode-se verificar que são diversas e variadas entre si. A Figura 1 mostra algumas
destas características.
Dados dentro do Big Data podem ser coletados sob diversas formas, Por exemplo, sob
a forma de atualizações em redes sociais (Facebook, Instagram), mapeamento remoto (Google
Maps, GPS), fotos (Flickr), vídeos (Youtube), ferramentas de busca (Google, DuckDuckGo),
entre outras. Todas essas formas de dados formam um subconjunto Big Data conhecido como
dados não-estruturadas. Cada pessoa, hoje em dia, é um produtor de dados em potencial. As
tecnologias mais tradicionais, que processam dados estruturados, tais como bases de dados
estruturadas, não servem completamente para o armazenamento e processamento no ambiente
Big Data. As novas tecnologias (armazenagem, memória, processamento e largura de banda)
que surgiram nos últimos anos foram as grandes impulsionadoras da análise de dados no
contexto Big Data (ARELLANO, 2013).
FIGURA 1 – Conteúdo Big Data

Fonte: Os autores

Além disso, o desenvolvimento dos processos de virtualização e a distribuição de
produtos/serviços dentro dos ambientes colaborativos requerem a integração de processos e a
interoperabilidade semântica de dados e informação, bem como o uso de ontologias para
facilitar tal integração. Há uma série de tarefas potencialmente beneficiárias do uso de
ontologias no contexto da integração logística numa cadeia de suprimentos. Representar
formalmente um processo, produto ou serviço significa dar um passo fundamental na direção
de se remover a ambiguidade, que é um problema crucial no ambiente Big Data. Além disso,
uma boa representação ontológica permite inferir e recuperar a informação que não está



explícita à primeira vista, o que possibilita identificar qualquer situação conflitante ou
inconsistente dentro do contexto das relações entre as entidades do sistema. Com uma longa
tradição nos campos da Filosofia, Ciência da Computação e Ciência da Informação, as
ontologias provêm suporte para a engenharia do conhecimento e para a inteligência artificial,
por meio da modelagem das diversas áreas do conhecimento em termos de conceitos,
atributos e relações,

geralmente classificadas em relações hierárquicas do tipo

especialização/generalização (SIMPERL, 2009; MCKINSEY GLOBAL INSTITUTE, 2011).
4 MODELO BIGLOGDATIX
Este trabalho é uma pesquisa aplicada, que propõe um modelo conceitual para
combinar práticas de gestão com a aplicação de técnicas de Big Data para aquisição e análise
de dados dentro de um contexto de Sistemas Ciber-físicos da Logística.
As modernas organizações que estão envolvidas em projetos de desenvolvimento de
novos produtos/serviços, para continuarem competitivas, deveriam adotar métodos flexíveis
de trabalho de maneira a satisfazer as numerosas e variadas demandas do mercado global.
Esta flexibilidade deveria não somente se constituir da capacidade de oferecer boas respostas
aos seus clientes, mas também da capacidade de se detectar potenciais mudanças e futuras
tendências em todo o sistema. No cenário dos sistemas ciber-físicos, esta estratégia significa
combinar e coordenar todos os atores envolvidos – humanos e não-humanos –, desde a
entrada da matéria-prima até a entrega do produto/serviço final.
Esta combinação depende do complexo processo de integração de três problemas
essenciais: computação, controle e comunicação (CYBER-PHYSICAL SYSTEMS, 2012).
Integrar estas três dimensões significa considerar os diferentes participantes e seus pontos de
vista, diferentes áreas de conhecimento, diferentes topologias de rede e equipamentos,
diferentes requisitos e diferentes estágios de atividades locais e globais. Quando este processo
é completado com sucesso, ele é capaz de produzir um sistema autoadaptável e mais ágil.
O modelo proposto (Figura 2) procura satisfazer critérios reativos e pró-ativos, pois o
mesmo processa não somente informação de feedback (por exemplo, opinião de consumidores
sobre determinado produto), como também procura revelar prognósticos e descobrir
informações que se configurem tendências. De maneira a manter este sistema sustentável e
escalável, considera-se que o compartilhamento de informação é um atributo fundamental,
pois fornece entradas de dados pré-processadas a atores humanos e não-humanos, de maneira
que estes possam utilizá-las para tomar decisões melhores. As informações de feedback irão
permitir ajustes, correções e atualizações em todo o SCF. Informações do tipo prognóstico e



tendências futuras – inferidas e produzidas através de técnicas de análise – serão a base para
ações da organização visando inovação, antecipação e estratégias criadoras de valor, que
visam o ganho competitivo em relação aos competidores. Para que tal cenário seja alcançado,
o modelo BigLogDatix irá se beneficiar de técnicas de Big Data e Business Analytics.
Destacamos os esforços feitos para que o modelo BigLogDatix combine aspectos de
computação, controle e comunicação do Big Data, já que a integração destes três domínios é
um dos principais desafios da pesquisa nos SCF (CYBER-PHYSICAL SYSTEMS, 2012). O
BigLogDatix é estruturado em módulos distribuídos e ligados em rede. Cada um desses
módulos é configurável e instanciável para um cenário específico da cadeia de suprimentos.
Isto é, estes módulos são customizáveis para diferentes atores da logística, tais como o
controle do chão de fábrica, o gestor da relação com o consumidor, o grupo de BA, entre
outros. Apesar das circunstâncias serem diferentes, os métodos e técnicas utilizados são
similares.
FIGURA 2 – Módulo BigLogDatix

Fonte: Os autores.

Um Data Warehouse é proposto para integrar os dados coletados nas diferentes
origens. Este repositório central será alimentado através de processos ETL (extract,
transform, load), que transformarão os dados de seus formatos previamente coletados em
formato BigLogDatix. Além disso, propomos igualmente uma representação ontológica da
informação, de maneira que se possa efetuar um processo de inferência da informação e do
conhecimento. O resultado deste motor de inferência irá alimentar uma Base de



Conhecimento, que será utilizada para a descoberta e reconhecimento de informações e
conhecimentos tácitos. Bohn e Short (2010) dizem que:
[...] há muito critérios em potencial para medir o valor da informação,
incluindo julgamento subjetivo, preço de venda, disposição dos
consumidores em pagar, custo de desenvolvimento tamanho do público. Mas
não há maneira de comparar valor, especialmente quando se compara
informação de diferentes tipos.

Considerando esta afirmação, propomos uma máquina de inferência para inferir e
comparar, a partir de representações ontológicas, o valor da informação.
Desta forma, o modelo conceitual BigLogDatix pretende apoiar o processo de tomada
de decisão no contexto Big Data. Consideramos que os problemas não têm apenas uma
existência física, mas que eles dependem da intervenção de um ou mais atores humanos e
não-humanos que interagem por meio dos processos de comunicação, controle e computação,
dentro da tomada de decisão nos SCF aplicados à logística.
5 CONCLUSÕES
Consideramos estar no limiar de uma grande mudança da maneira pela qual decisões
são tomadas dentro das organizações. Podemos estar testemunhando um período no qual a
micro-segmentação de tempo-real de cidadãos e consumidores irá atingir o seu pico, através
da evolução e do uso das técnicas de Big Data e Business Analytics. Estratégias sofisticadas
de análise podem melhorar substancialmente o processo de tomada de decisão, minimizar
riscos e descobrir informações importantes, que de outra forma permaneceriam ocultas.
AGRADECIMENTOS
Este trabalho foi parcialmente financiado pelo CNPq (Conselho Nacional de
Desenvolvimento

Científico

e

Tecnológico),

no

escopo

da

chamada

MCTI/CNPq/MEC/CAPES – 43/2013, que apoia financeiramente projetos que visem
contribuir significativamente para o desenvolvimento científico e tecnológico e para a
inovação do País nas áreas de Ciências Humanas, Sociais e Sociais Aplicadas.
