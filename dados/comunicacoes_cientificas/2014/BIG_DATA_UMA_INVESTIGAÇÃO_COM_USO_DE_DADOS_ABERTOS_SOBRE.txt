
BIG DATA: UMA INVESTIGAÇÃO COM USO DE DADOS ABERTOS SOBRE
ACIDENTES DE TRABALHO
Resumo: O tema Big Data tem despertado interesse nos profissionais que trabalham com a
Gestão da Informação, pois trata de insumo essencial no processo de criação do
conhecimento. Este relato apresenta o tema e explora os fundamentos que auxiliam no
entendimento da abordagem de Big Data. Discute a explosão informacional e a avalanche de
dados, chegando aos elementos que compõem o tema. Aborda os 4 Vs do Big Data e as fases
de Discovery, Data Preparation, Model Planning e Analytics. O processo de pesquisa se
baseia em um estudo exploratório desenvolvido por meio de pesquisa bibliográfica com
análise documental. O marco empírico para análise dos elementos do domínio foi baseado no
site de Dados Abertos da Dataprev, bem como com outras informações disponíveis em redes
sociais e blogs especializados. Apresenta os resultados preliminares sobre estudos nas fases
iniciais de projetos de Big Data, de forma a viabilizar alternativas para representação e
disseminação dos grandes volumes de dados presentes na Internet. Ao final, apresenta alguns
aspectos ligados ao perfil do profissional que está participando destes projetos.
Palavras-chave: Big Data. Gestão da Informação. Análise de Dados. Dados Abertos.
Profissional de Informação

1 INTRODUÇÃO
O uso de dados e informação sempre foi objeto de estudos para a área de Ciência da
Informação. Desde a década de 1940, quando, principalmente em decorrência da 2a. Guerra
Mundial, novas pesquisas que foram impulsionadas pela indústria bélica geraram o “Caos
Documental” ou ainda a “Explosão Informacional” (RIBEIRO, 2008), os profissionais
envolvidos com pesquisas na área de CI sempre estiveram presentes em trabalhos ligados à
temática (SARACEVIC, 1996a).

Aliado a isso, percebe-se um outro deslocamento nos estudos sobre Gestão de Dados e
Informação. O uso cada vez maior de dispositivos móveis tem contribuído para incrementar a
“avalanche de dados”, uma vez que celulares e tablets que atuam como geradores e
consumidores de dados e informação estão presentes no nosso cotidiano. Esse movimento tem
sido conhecido como Big Data e vem despertando o interesse por todas as pessoas que tem
algum envolvimento com atividades para Gestão da Informação110.
Outro tema que tem motivado debates e investigações é a possibilidade de fazer
análise deste vasto volume de dados. Um exemplo recente sobre o uso dessa abordagem vem
do esporte. Em reportagem veiculada por meios de comunicação sobre a seleção da
Alemanha, vencedora da Copa do Mundo no Brasil, houve registro sobre a utilização de
solução que permitisse a análise de dados sobre jogos, jogadores, táticas de jogo e a
possibilidade de avaliar comentários especializados. Ou seja, o uso de dados e informação em
quantidade como forma de melhorar o desempenho do time alemão (SAP, 2014).
Pode-se afirmar que não está se propondo algo totalmente novo com o tema Big Data,
pois o uso de informação para a obtenção de resultados não é uma coisa nova. As abordagens
exploradas nos últimos anos pela Ciência da Informação vêm contemplando diferentes visões
em Sistemas de Apoio à Decisão (EIS), Armazéns de Dados (Data Warehouses e Data Marts),
Desempenho dos Negócios (Business Intelligence), soluções para Mineração de Dados (Data
Mining), além de informação para planejamento estratégico, gestão de recursos
informacionais e ativos de informação na Web. Fazendo uma análise preliminar destes
movimentos, é licito supor que o profissional de informação deve refletir um pouco sobre
como poderá se envolver nas discussões sobre o tema Big Data (RIBEIRO, 2014).
Dentro deste contexto, este relato apresenta alguns resultados preliminares sobre o
envolvimento de profissionais da informação nas fases iniciais de projetos de Big Data, de
forma a viabilizar alternativas para representação e disseminação dos grandes volumes de
dados presentes na Internet.
2 A AVALANCHE DE DADOS COMO CATALISADOR DE BIG DATA
O tratamento e uso da informação pela sociedade têm se modificado nas últimas
décadas como consequência do surgimento de novos modelos sociais, econômicos ou
tecnológicos. A crescente utilização de meios de comunicação com alto grau de mobilidade e
o uso cada vez maior da Internet, definem outros espaços e demarcam novas fronteiras para a
110

O relato aqui apresentado é parte do projeto de pesquisa do autor e está apoiada no Referencial
Teórico desenvolvido em (RIBEIRO, 2014)



sociedade contemporânea (RIBEIRO, 2008). Ficou evidenciado o estado de insatisfação dos
usuários nas pesquisas desenvolvidas por Wurman (2005) - onde reafirmou-se um sentimento
de “Ansiedade da Informação” – e por Gopinath e Das (1997) – onde estabeleceu-se uma
percepção sobre a “Explosão Informacional”.
Heath e Bizer (2011) reforçam essa ideia quando observam que na atualidade estamos
cercados por uma grande quantidade de dados e informação. São registros sobre o cotidiano –
desempenho da educação, produção de bens e serviços, investimentos e impostos
governamentais, estatísticas sobre a economia e dados sobre o consumo - que nos auxiliam a
tomar decisões e gerar conhecimento.
Mas afinal, o que está impulsionando esta avalanche?
Alvin Tofler, em seu livro publicado em 1984 sobre as mudanças do comportamento
da sociedade pós-moderna, cunhou o termo prosumer111 (TOFLER, 1984), para definir o
novo perfil de interação da sociedade de consumo. É possível afirmar que com o avanço do
uso de dispositivos móveis, esta forma de interação começou a se concretizar. O uso de
sensores industriais e biomédicos, fotos, vídeos, e-mails, redes sociais, além do comércio
eletrônico, interações via call centers, dados públicos imagens médicas e outros dados
científicos, câmeras para monitoramento, medidores inteligentes, GPS, aplicativos para troca
de mensagens, aplicações que nos ajudam a pegar táxis, outras que nos ajudam na locomoção
urbana evitando engarrafamentos, ou ainda no monitoramento de ônibus e até de aviões, são
exemplos claros dos efeitos desta avalanche (RIBEIRO, 2014).
Complementarmente, é possível perceber também uma mudança no funcionamento
das aplicações de comércio eletrônico. A ampliação do uso de sistemas de recomendação112
na Web, permite que sejam indicados dezenas de opções de compras aos clientes usuários
destes serviços. Aliado a isto, tem-se que a previsão da expansão das fontes de dados é de
aproximadamente 50 vezes nos próximos 10 anos. Segundo previsões apresentadas pela
empresa EMC, instituição especializada em armazenamento de dados, o crescimento de dados

111

112

Neologismo criado por Alvin Tofler que representa a união dos conceitos de produtor e
consumidor
Em um sistema de recomendação, parte-se de perfis de usuários específicos, que podem ser
agrupados e relacionados a outros perfis que, quando incrementados com seus respectivos
históricos de compras e com os dados originados pelas redes sociais, possibilitam a descoberta de
produtos a serem ofertados (FLORISSI, 2014).


e informações digitais no mercado brasileiro crescerá de 212 Exabytes113 em 2014,
alcançando a marca de 1.6 Zettabytes (1.600 Exabytes) em 2020 (EMC, 2014).
Fruto deste cenário, rico em volume e variedade de fontes, tem surgido uma disciplina
que, apesar de não ser apenas um tema essencialmente tecnológico, vem sendo impulsionado
pelos projetos de tecnologia: a vertente de Big Data (RIBEIRO, 2014).
3 REFERENCIAL TEÓRICO
Fox e Hendler (2011) também anteciparam que estamos vivendo com uma nova
abordagem chamada de “Big Data”. Esta abordagem está surgindo em decorrência da
geração, e, consequentemente, da necessidade da coleta de grande volume de dados com
formatos variados. Ademais, estes dados ainda precisam ser geridos e, neste sentido, Fox e
Hendler continuam e observam que a gestão destes recursos possibilitará a resolução de
problemas que nem sabíamos que existiam. No entanto, vale ressaltar que não podemos
prescindir de ferramentas, pois a capacidade do ser humano de analisar dados e informações
com múltiplas facetas é limitada. Logo, são necessários alguns instrumentos que nos auxiliem
a executar estas tarefas.
3.1 A noção de big data
A necessidade de vencer o desafio, reunindo e analisando fontes de diversas naturezas,
deu origem a pesquisas que nos levaram ao tema “Big Data”. Estas pesquisas foram
desenhadas a partir de três aspectos iniciais (DAVENPORT, 2014):
A múltipla natureza dos dados – aspecto relacionado com as diferentes fontes
disponíveis.
O uso de processamento em nuvem – aspecto relacionado ao uso ilimitado de recursos
computacionais e com processamento em larga escala, com a possibilidade de redução de
custos (economia de escala – é o aspecto econômico-financeiro).
Uso de tecnologias específicas, tais como processamento de rotinas em paralelo e
ferramentas para otimização como Hadoop114 e MapReduce115, HDFS116, além de abordagens
de MachineLearning117 e Analytics118.

113

114

Em valores aproximados a unidade Exabyte é equivalente a cerca de1.000 Petabytes, ou ainda, a
1.000.000 de Terabytes.
Hadoop é tecnologia open source desenvolvida pela Google e Yahoo para processar muitos dados
em servidores, usando a noção de processamento em paralelo e uso de clusters (conjuntos) de
computadores no processamento. Pode ser chamado de Apache Hadoop e também foi
desenvolvido e customizado por outros fabricantes (EMC, Intel, Microsoft, dentre outros).


A abordagem de Big Data está apoiada em quatro outros fatores de sustentação,
conhecidos como os 4 Vs do Big Data: Volume, Variedade, Velocidade e Veracidade
(DUMBILL, 2012). A seguir será apresentado um breve esclarecimento do papel de cada um
desses componentes:
O primeiro V é de Volume e está ligado ao grande quantitativo de dados e
informações que nos cercam no cotidiano. Já o segundo V está ligado à variedade destes
recursos.
Devido a forte relação entre Volume e Variedade, estes fatores serão comentados em
conjunto. A multiplicidade de dispositivos e a capacidade destes dispositivos interagirem em
rede está promovendo a verdadeira inundação de dados. Cada um de nós carrega junto de si
um celular, que agindo como um sensor, pode enviar informação de localização das pessoas e
permitir a realização de negócios direcionados119. Ao levarmos em consideração que o
mundo tem cerca de 7 bilhões de habitantes (WIKIPEDIA, 2014) e que aproximadamente 6
bilhões possuem celulares (ONUBR, 2014), pensem no volume e na variedade de dados que
pode ser gerado, captado, processado, (re)utilizado e entregue.
As cidades estão repletas de câmeras de monitoramento nos prédios, lojas, ruas e
avenidas. Qualquer cidadão pode gravar e postar um vídeo em mídias sociais ou no Youtube.
Estima-se que a quantidade de vídeos produzidos diariamente ultrapassa a produção dos
primeiros 50 anos de televisão (DAVENPORT, 2014).
Saindo do cotidiano e observando o ambiente de ciência e tecnologia, temos muitos
outros exemplos. Os projetos de pesquisa de perfuração de petróleo em águas profundas,
incluindo o pré-sal (CIARINI, 2013; SANTOS, 2014), além de projetos de pesquisa em
astronomia, estão impulsionando o uso da abordagem de Big Data (PORTO, 2013).

115

116

117

118

119

MapReduce é o framework arquitetural que deu origem à tecnologia de Hadoop. Usa a estratégia
de dividir para conquistar, ou seja, distribui e aloca um problema muito grande em clusters de
armazenamento, usando registros serializáveis do tipo <chave, valor>.
HDFS é a sigla de Hadoop File System. É uma estrutura de armazenamento de arquivos que
utiliza blocos de 128 Mbytes, que são muito menores do que os blocos de particionamento
tradicionais, utilizados em dispositivos de armazenamento.
Machine Learning trata o uso de algorítimos que identificam o melhor modelo para ser aplicado
ao conjunto de dados.
Analytics é a essência de Big Data. Trata a análise dos dados e será apresentada mais à frente
neste relato.
Um exemplo para a prática de negócios direcionados é o e e-couponing. Esta prática possibilita o
envio de cupons de desconto em tempo real para os usuários, quando os mesmos estão nas
proximidades das lojas, utilizando-se as coordenadas GPS dos celulares dos usuários (FLORISSI,
2014).



Adiciona-se a esse cenário, uma vasta coleção de outras fontes e formas para geração
de unidades documentárias. O crescimento do uso de documentos digitais e páginas Web nas
organizações, recursos estes estruturados por meio de ferramentas para Gestão de Conteúdo
(RIBEIRO, 2012), bem como o desenvolvimento de propostas de uso da Web of Data e
Linked Data (RIBEIRO, ALMEIDA, 2011; RIBEIRO, VIEIRA, 2014) também têm
contribuído para um aumento em Volume e Variedade de dados e informação.
Voltando aos 4 Vs do Big Data, chega-se agora ao terceiro V, de Velocidade. A
melhoria dos canais de transmissão, com redes em fibra ótica e emissores de sinais de alta
capacidade, o uso de satélites, o uso de outras bandas para a telefonia celular, as
comunicações em tempo real para controle de processos na internet, os workflows científicos
com processamento paralelo e cluster de processamentos vem possibilitando atingir uma
maior velocidade para troca de dados e informação (MATTOSO, 2013). Ademais, é possível
afirmar que a velocidade continuará crescendo, pois o desenvolvimento da tecnologia de
processadores, dos canais e do hardware para armazenamento (discos rígidos e memória
rápida – flash memory), duplica o seu poder a cada período de 2 anos (FLORISSI, 2012).
O quarto V é de Veracidade. A qualidade dos dados e informação é característica
essencial para que os usuários interessados (executivos, gestores públicos e a sociedade em
geral) usem e (re)usem os dados de maneira apropriada e real, gerando informações críveis
para eles mesmos.
Para concluir a noção de Big Data ainda vale explorar um componente que faz parte
do terceiro aspecto relacionado anteriormente por Davenport. A discussão sobre o trabalho de
análise dos dados, entendidos pela noção de Big Data Analytics.
3.2 Big data analytics
O objetivo da tarefa de Analytics é executar a análise preditiva dos dados por meio da
execução de mining (minerações)120. Segundo os autores Oliveira (2013) e Tavares (2014),
inicialmente, serão tratados os dados com o uso de técnicas estatísticas, para separação e
reunião de conjuntos (denominado de fase de discovery).
Adicionalmente, para executar a tarefa também pode-se fazer uso de técnicas para
categorização, limpeza e transformação dos dados, utilizando, inclusive, a visão da
proveniência (fontes de origem) dos dados para auxiliar no processo de categorização. Ao
final desta fase é possível chegar à definição e preparação de modelos (fase de data
120

A noção de mining de dados passa pela extração e análise de grandes volumes de informação em
busca de padrões e comportamentos.


preparation e model planning) que serão úteis na construção do grande conjunto de dados,
chamado de lago de dados (data lake).
A carga de dados (denominada fase de ingest) ocorrerá em seguida e será realizada
para povoar o lago de dados. No lago estarão reunidos todos os dados que serão alvo de
análise. Por fim, os resultados que serão obtidos a partir do tratamento e análise do conteúdo
do lago serão apresentados com uso de ferramentas de visualização e deverão estar associados
ao contexto de negócios (OLIVEIRA, 2013; TAVARES, 2014).
A análise de dados que atendem aos requisitos descritos anteriormente (lembrem-se
dos 4 Vs), precisará ser desenvolvida segundo uma nova arquitetura de análise, onde dados
serão obtidos de múltiplas fontes e em tecnologias diversas. O ponto central desta análise está
ligado à capacidade de correlacionar dados, pois, como já observado, o ser humano possui
limitações para fazer análises associadas a múltiplas dimensões. Em essência, quando temos
uma pequena quantidade de dados (little data) não temos muita dificuldade de correlacionálos, pois existem poucas inter-relações. Mas, com uma grande quantidade (big data), temos
muitos dados sendo gerados em paralelo, logo, surge a dificuldade para correlacioná-los
(SEYMOUR, 2014).
Para Sathi (2013), o trabalho com os processos de negócio de uma organização
começa a prescindir de um profissional que saiba executar tarefas ligadas à fase de Analytics,
de forma que seja possível desenvolver novos produtos e serviços para os clientes e/ou
usuários.
3.3 O cientista de dados e a fase de discovery
O surgimento desta nova arquitetura de análise, impulsionou o processo para formação
de um perfil profissional que passou a ser denominado de Cientista de Dados (Data Scientist).
A característica principal deste profissional é ter a capacidade de aplicar ferramentas
analíticas e algoritmos para gerar previsões sobre produtos e serviços (DAVENPORT;
PATIL, 2012). Oliveira (2013) complementa e detalha que este perfil deve ter forte
conhecimento em disciplinas como a matemática e a estatística, com treinamento avançado
em estratégias para tratamento de grandes conjuntos de dados, fazendo uso de modelos
matemáticos, formulação de hipóteses e técnicas de regressão. Já Brietman (2014) observa
que o Cientista de Dados deve ter capacidade de levantar requisitos dos usuários, buscando
não apenas nas necessidades destes usuários, mas também nos outros envolvidos no ambiente
sob análise (clientes, parceiros de negócio, informações de mercado, feeds de notícias, redes
sociais, blogs, dentre outros).


Para Oliveira (2013), o cientista de dados deve ser um técnico cético, curioso, criativo,
comunicativo e deve saber trabalhar em colaboração. Ademais, o cientista de dados deve
sempre (re)avaliar questões durante as primeiras fases do desenvolvimento do trabalho.
Oliveira continua e apresenta questões que podem auxiliar na revisão das fases de
Discovery, Data preparation e Model Planning. No entanto, daremos ênfase na fase de
Discovery, por ser o recorte adotado para esta pesquisa.
As principais questões apresentadas para a fase de Discovery são: eu possuo o
conhecimento suficiente do ambiente de dados e informação? Eu tenho informação suficiente
para esboçar um plano analítico e compartilhar com meus pares? Eu consigo desenvolver
trabalhos para organização para tipos de problemas? Categorizações e classificações de
dados? Projeto de conjuntos (clusters) de dados? Eu consigo esboçar e realizar entrevistas
para conhecer o contexto e domínio que será trabalhado? Eu posso identificar as diferentes
fontes de dados?
Em suma, os projetos de Big Data são desenvolvidos com os objetivos de criar novos
produtos, compreender necessidades dos clientes e seus comportamentos, bem como perceber
novos mercados. Para isto, é necessário desenvolver teorias para tratar com clientes e
usuários, construindo hipóteses e identificando dados e informações relevantes. Este processo
deve ser repetido e refinado, de acordo com os experimentos realizados e as respostas obtidas
(MARCHAND; PEPPARD, 2013).
4 METODOLOGIA
O recorte deste estudo contempla o uso de recursos ligados a organização do
conhecimento para auxiliar no desenvolvimento de projetos de Big Data, conforme requisitos
apontados (ver 3.1 e 3.2).
Trata-se de um estudo exploratório e tendo em vista o recorte adotado, buscou-se
identificar na primeira fase da pesquisa os conjuntos de dados e de informação que possuem
correlação com a temática de Acidentes de Trabalho. Esta primeira fase foi desenvolvida
sobre o conteúdo do portal de Dados Abertos da Dataprev121.
Com o intuito de complementar os conjuntos levantados, na segunda fase serão
reunidos outros sítios específicos na internet e rede sociais que debatem temas correlatos com
o assunto.

121

Disponível em http://dadosabertos.dataprev.gov.br


As questões sobre a relevância da informação tratadas por Saracevic (1970; 1996b)
são utilizadas para auxiliar na definição dos conjuntos de interesse. Os itens relevantes, em
geral, responderam a questões que podem ser de interesse para o cliente e/ou usuário. Estas
questões devem ser desenvolvidas com o apoio de critérios, sintetizados a seguir (RIBEIRO,
2012):
•

As informações ou os conjuntos de dados selecionados ocasionam sentimentos de
excitação e satisfação aos clientes e/ou usuários;

•

Especificidade das pesquisas realizadas pelos clientes e/ou usuários estão
contempladas nos conjuntos selecionados;

•

As respostas esperadas cobrem conceitos que estão presentes nas suas pesquisas.

Com uma primeira versão de escopo definido, passou-se a observar as questões
apresentadas (ver 3.3) com o intuito de avaliar os conjuntos e correlações identificadas.
5 O EXPERIMENTO SOBRE OS DADOS DE ACIDENTES DE TRABALHO
A Previdência Social é detentora de muitos dados e informações da sociedade
brasileira. Com o esforço para publicação de dados em formato aberto para poderem ser
reutilizados pela sociedade (RIBEIRO, ALMEIDA, 2011), surgiram muitas possibilidades de
reuso, tanto em projetos de pesquisa específicos quanto em trabalhos acadêmicos
(FERREIRA; SANTANA; VIDOTTI, 2012; RODRIGUES, 2012; CAMPOS; CAMPOS;
CARVALHO; LIMA, 2012; ROCHA; CHAVES, 2013; GERMANO, 2013).
Esta investigação está sendo desenvolvida no âmbito de um projeto de pesquisa em
curso na Unirio e está apoiada em trabalhos anteriores desenvolvidos pelo autor. O objetivo
deste estudo é investigar um conjunto de atividades que viabilizem a participação do
profissional da informação na fase de Discovery de projetos de Big Data. Assim, a
delimitação do campo empírico se deu a partir da questão: é possível analisar os dados abertos
sobre Acidentes de Trabalho disponíveis no portal da Previdência e correlacioná-los com
comentários de blogs específicos e/ou redes sociais, para gerar análises que possibilitem a
construção de políticas de prevenção?
Para Oliveira (2013) as duas primeiras etapas para executar o trabalho de Discovery e
entendimento são: a identificação das informações que serão necessárias para possibilitar
interpretações sobre os resultados, correlações, implicações e causalidade; e determinar o(s)
tipo(s) de organização para estas informações (classificações e clusterizações).



Na tarefa de entendimento a elaboração de modelos de dados é útil, pois permite
avaliar, inclusive, a possibilidade de realizar integrações de dados e associações. Sukumar e
Ferrel (2013) convalidam esta estratégia quando afirmam que conhecer estrutura dos dados e
seus relacionamentos, podem facilitar o trabalho de análise de conjuntos de dados.
Assim, a investigação partiu da identificação dos dados e informações relevantes no
Portal de Dados abertos da Dataprev e, neste sentido, foram identificados dois conjuntos de
dados que poderiam ser úteis para responder a questão de partida: Acidentes de Trabalho por
CBO122 e Acidentes de Trabalho por CNAE 2.0123. A representação a seguir (Figura 1) foi
gerada a partir de uma extensão do modelo obtido em (RIBEIRO, ALMEIDA, 2011).
FIGURA 1: Modelo de Dados dos conjuntos escolhidos
Ano

CBO

CNAE

tem

ocorre

Quantidade de Acidentes de
Trabalho

C/CAT

tem

S/CAT

Doença

Típico

Trajeto

Fonte: o autor

Os componentes desse modelo (entidades, relacionamentos e atributos) serão
utilizados na avaliação do conteúdo dos comentários, pois permitem alguma representação
semântica dos dados e informação contemplados pela modelagem.

122
123

Classificação Brasileira de Ocupações
Classificação Nacional de Atividade Econômica


Cabe registrar que o modelo de dados permite representação semântica na medida em
que este modelo apresenta elementos (entidades e atributos) e relações em um determinado
domínio (CAMPOS, 2001). Campos, Campos, Carvalho e Lima (2012) reafirmam a estratégia
de modelagem conceitual, pois permite uma boa forma de efetuar a representação do
conhecimento em um domínio.
Vale ressaltar que conforme apresentado (ver 4) a complementação dos dados e
demais correlações será desenvolvida na próxima etapa, quando serão investigados e
trabalhados os dados originários de blogs e redes sociais, tomando-se por base os conceitos
presentes no modelo de dados. Nesta direção, o uso de aplicações para fazer o monitoramento,
tais como Socialmention (www.socialmention.com) e Topsy (www.topsy.com), possibilitará a
coleta, organização e categorização das informações obtidas nas redes sociais, construindo
uma proposta para representação de dados e informação na fase de Discovery. Já foram
identificados, preliminarmente, os seguintes endereços, que irão nortear a delimitação das
informações relevantes:
• https://www.facebook.com/revistaprotecao
• https://www.facebook.com/TSTJus?ref=ts
• http://nrfacil.com.br/blog/?cat=172
• http://atdigital.com.br/direitoprevidenciario/category/acidentes-do-trabalho/
• http://seguranca-trabalho-tst.blogspot.com.br
• http://blog.pesquisasaude.com/dia-nacional-da-preveno-de-acidentes-trabalho/
Shiri (2014) convalida a proposta aqui formulada para análise de informação na fase
de Discovery, quando apresenta facetas e sub-facetas para análise de grandes volumes de
dados. Apoiado em tipos de dados e no contexto dos conjuntos sob análise, além da estrutura
dos dados e dos metadados, Shiri propões estender práticas de organização e representação do
conhecimento para trabalhos com Big Data.
O trabalho de análise dos dados e informação originários de redes sociais pode ser
melhor estruturado com o apoio de uma Ontologia, pois esta pode guiar a identificação dos
objetos, suas características, propriedades e contextos que serão fundamentais no processo de
organização (PORTO, BAX, FERREIRA, SILVA; 2012). No entanto, pretende-se com este
estudo avaliar a possibilidade de uso de outras formas de representação, que podem apontar
caminhos alternativos à investigação, contribuindo para a evolução de métodos de
representação na fase de Discovery e com a participação de profissionais da informação.



6 CONSIDERAÇÕES FINAIS
O uso das abordagens ligadas ao tema Big Data ainda carece de investigação pela área
de Ciência da Informação. O uso dessas abordagens poderá auxiliar na melhoria da oferta de
serviços de informação, pois conhecer o ambiente de dados e informação que deve ser
originário de diferentes fontes, efetuar a organização de conjunto de dados (categorizá-los?),
realizar entrevistas junto aos clientes e/ou usuários e desenvolver os modelos (tanto
estruturais quanto matemáticos), contribuirá para o projeto desses serviços.
Para Minelli, Chambers e Dhiraj (2013), o momento que vivemos é especial, pois a
contínua redução do custo dos equipamentos, além do uso de novos softwares e ferramentas
para apoiar os processos de gestão de dados e informação, têm contribuído para um momento
especial no tratamento da informação.
Quando lançamos um olhar na direção das bibliotecas e unidades de informação, é
possível perceber que tanto os estoques existentes quanto as demandas por outras fontes têm
crescido de forma exponencial, pois os ativos de informação de interesse para os usuários
estão armazenados em diferentes bases de dados, usando bancos de dados e plataformas de
computação heterogêneas (MELETIOU, KATSIRIKOV; 2009). Adicione-se a isso, a
presença cada vez maior de redes sociais e aplicações de colaboração nos serviços das
unidades de informação (DE JESUS, DA CUNHA; 2012; SANTOS, DA ROCHA; 2012),
ocasionando mudanças no comportamento dos usuários. Em suma, compreender e participar
de esforços com o uso de Big Data pode ser valioso para auxiliar na estruturação de unidades
de informação.
Espera-se que este movimento de pesquisa sobre o tema Big Data na área da Ciência
da Informação, ilumine o caminho a ser trilhado e possibilite que outros pesquisadores
interessados possam se engajar nesta discussão, levando os debates sobre este tema para além
da tecnologia.
