

COMPARANDO MÉTODOS DE AVALIAÇÕES DE USABILIDADE,
ENCONTRABILIDADE E DE EXPERIÊNCIA DO USUÁRIO

Modalidade da apresentação: Comunicação Oral
Resumo: tem como objetivo identificar quais aspectos são considerados em avaliações de usabilidade,
encontrabilidade e experiência do usuário em sistemas de informação. Esta pesquisa tem duas questões
centrais: (i) Qual é a diferença entre os diversos tipos de avaliações de interação humano-sistema e se
(ii) existe diferença entre métodos que não consideram as impressões do usuário daqueles que
consideram? Para responder a estas perguntas foram avaliados quatro tipos de testes nos quais dois
não consideravam as opiniões do usuário (Avaliação Heurística e a Avaliação de Encontrabilidade) e
outros dois eram exclusivamente baseados nas impressões destes (Teste de Usabilidade - SUS e o
Teste de Experiência do Usuário). Os métodos escolhidos foram: (i) avaliação heurística de Nielsen,
(i) avaliação da encontrabilidade baseadas na análise da tarefa e Keystroke Level Method (KLM), (iii)
avaliação de usabilidade SUS (System Usability Scale) e (iv) avaliação da experiência do usuário
baseado no UEQ (User Experience Questionnaire). As avaliações foram realizadas em duas
funcionalidades de um sistema de gestão acadêmico e para cada uma delas, foi analisado como sete
aspectos eram avaliados: (i) interface, (ii) localização, (iii) efetividade, (iv) custo, (v) intuitividade,
(vi) utilidade e (vii) experiência. Foi observado que cada método de avaliação, sozinho, observa um ou
dois dos aspectos analisados e que a utilização conjunta dos métodos promove maior abrangência na
avaliação aspectos escolhidos. Também foi observado que os métodos de avaliação são mais
influenciados pelo seu propósito do que por quem fará a avaliação, reconhecendo que testes baseados
nas respostas dos usuários são imprescindíveis para observar impressões qualitativas do usuário,
tornando essa abordagem obrigatória em alguns testes.
Palavras-chave: Usabilidade; Avaliação Heurística; Encontrabilidade; Experiência do Usuário.

1 INTRODUÇÃO
A relação entre humanidade e informação foi “radicalmente” alterada, não só pelo
surgimento da Internet, mas pelo contexto SMAC (Social, Mobile, Analytic e Cloud),
proporcionado pela tecnologia contemporânea que permite aos usuários livre e ilimitado
acesso à informação, independente de lugar (onde), de tempo (quando) e do dispositivo
utilizado (como) (MEIRA, 2015). Devido a isso, houve um aumento no número de pesquisas
referentes aos processos informacionais existentes em ambientes digitais, pois, de acordo com
Vechiato (2013, p. 35) "em um primeiro momento, tais ambientes foram construídos
essencialmente sob uma perspectiva top-down (um para muitos), com enfoque na
disseminação de informação de uma determinada organização, pessoa ou área do
conhecimento para o público em geral".
Apesar da realização de muitas tarefas em ambientes digitais requererem a interação
dos usuários, Preece et al. (2005, p. 24) afirma que muitos produtos "não foram
necessariamente projetados tendo o ser humano em mente. Foram tipicamente projetados
como sistemas para realizar tarefas que podem funcionar de maneira eficaz, olhando-se da
perspectiva da engenharia", fazendo com que, muitas vezes, os usuários precisem se adequar
aos sistemas que farão uso.
Esse cenário de inadequação dos projetos de software vem instigando pesquisadores a
desenvolver pesquisas cujo objetivo seja tentar garantir que os sistemas se tornem mais
usáveis aos seus usuários. Para isso, vem se trabalhando a estruturação da informação e a
aplicação de princípios da usabilidade nas etapas iniciais de desenvolvimento das interfaces5,
podendo proporcionar uma

melhor utilização futura do sistema pelos usuários

(VALDESTILHAS; ALMEIDA, 2005).
Nesse contexto, a motivação do presente trabalho se originou nas reclamações
constantes por parte dos alunos, em questões relativas à percepção de elementos, uso,
adequação e efetividade das atividades realizadas no sistema de gestão acadêmica Sig@ 6
utilizado na Universidade Federal de Pernambuco (UFPE).
Dessa forma, o objetivo geral deste trabalho é identificar diferentes aspectos
abordados por quatro tipos de testes de interfaces que são: (i) Avaliação Heurística de
Nielsen, (ii) Avaliação de Encontrabilidade usando os métodos Análise da Tarefa e Keystroke
Level Method (KLM), (iii) Teste de Usabilidade usando o System Usability Scale (SUS) e (iv)
a avaliação da experiência do usuário utilizando o User Experience Questionnaire (UEQ).
Ressalta-se que não é objetivo desta pesquisa realizar apenas as avaliações usando os quatro
métodos, e sim, entender que tipo de problemas cada um ajuda a encontrar em uma interface e
como eles podem auxiliar analistas de sistemas a tornar a informação mais acessível aos
usuários. Como exemplo de aplicação dos métodos foi usado como estudo de caso o sistema
Sig@UFPE. Este artigo está estruturado da seguinte forma: as Seções de 2 a 4 apresentam a
fundamentação teórica para a realização da pesquisa; a Seção 5 a metodologia utilizada para
realizá-la; a Seção 6 os resultados obtidos e, finalmente, na Seção 7 as considerações finais da
pesquisa.

5

A definição de interface que utilizamos nesse trabalho é aquela dada por Nielsen (1993): “a interface
do usuário deve ser entendida como sendo a parte de um sistema computacional com a qual uma
pessoa entra em contato — física, perceptiva ou conceitualmente”.
6 www.siga.ufpe.br



2 AVALIAÇÃO DE USABILIDADE
Segundo Nascimento (2006) A avaliação de usabilidade é um nome genérico para um
grupo de métodos baseados na avaliação e inspeção ou exame relacionado com aspectos de
usabilidade da interface com o usuário. Winkler e Pimenta (2002) classificam os métodos de
avaliação em dois grupos: os métodos de inspeção de usabilidade e os testes empíricos com a
participação de usuários. Para a realização dessa pesquisa foi escolhido um método de cada
um desses grupos. Entre os métodos de inspeção de usabilidade foi escolhida a avaliação
heurística, baseada nas heurísticas de Nielsen (1994). E no grupo dos testes empíricos foi
escolhida a aplicação do questionário SUS (System Usability Scale)
2.1 AVALIAÇÃO DE HEURÍSTICA
Nielsen (1994) afirma que a avaliação heurística é um método de avaliação de
usabilidade em que inspetores de usabilidade analisam características de uma interface
(especificações, protótipos ou o produto final) e examinam se elas atendem aos princípios
gerais de usabilidade, ou seja, as heurísticas. Em outras palavras, nesse tipo de avaliação um
avaliador interage com a interface e julga a sua adequação ou não a princípios de usabilidade
reconhecidos, chamados de heurísticas. Ou seja, o avaliador procura problemas de usabilidade
por meio da análise e interpretação de um conjunto de princípios. Chan e Rocha (1996, p.11)
definem cinco etapas para se realizar uma avaliação heurística (Figura 1).
FIGURA 1: Fases da Avaliação Heurística

Fonte: Baseado em Chan e Rocha (1996)
A primeira etapa se dá com a definição dos requisitos da avaliação onde são
escolhidos os avaliadores, o objeto, dos objetivos, as heurísticas avaliadas, o escopo da
avaliação e quais são os recursos necessários para a avaliação. A segunda etapa tem como
objetivo apresentar todas as informações definidas na primeira etapa aos avaliadores,
incluindo guidelines a serem utilizados e o material de apoio (formulários, exemplos,
4

manuais). Na terceira etapa realiza-se a avaliação da interface propriamente dita, onde os
avaliadores fazem a conferência das propriedades da interface frente ao que é recomendado
pelos guidelines. Na quarta etapa, promove-se a discussão entre os avaliadores e outros
envolvidos na avaliação que se reúnem para discutir quais foram os problemas detectados e
determinar a gravidade a estes problemas. Por fim, há a divulgação dos resultados aos
interessados, explicitando problemas encontrados, a gravidade de cada um e as
recomendações sobre essas questões.
Existem vários tipos de heurísticas que podem ser utilizadas para realizar uma
avaliação heurística. Porém, para esta pesquisa foram escolhidas as heurísticas de Nielsen
(1994), por existir abundante literatura sobre as mesmas. Por isso, apenas essas heurísticas
serão brevemente apresentadas a seguir (NIELSEN, 1994):
1. Visibilidade e reconhecimento do estado ou contexto atual do sistema: o
sistema deve dialogar com o usuário por meio de feedback apropriado, em
tempo razoável.
2. Compatibilidade com o mundo real: o sistema deve usar termos próximos ao
do usuário, utilizando palavras familiares e dispor as informações em ordem
lógica mantendo a coerência com o modelo mental do usuário.
3. Controle e liberdade do usuário: Dar ao usuário o controle do processamento
de suas ações, oferecendo a opção de desfazer e refazer operações.
4. Consistência e padrões: Contextos e situações similares devem apresentar
comportamentos similares. Uma ação deve ser representada por apenas um
ícone ou palavra e deverá ser formatada em todas as telas da mesma maneira.
5. Prevenção de erros: O sistema deve prevenir possíveis erros e corrigi-los,
caso ocorram.
6. Reconhecimento ao invés de memorização: A interface deve oferecer uma
ajuda contextual sendo capaz de orientar o usuário.
7. Flexibilidade e eficiência de uso: A interface deve se adaptar ao contexto ao
mesmo tempo prover eficiência de uso. O sistema deve ser fácil para usuários
leigos, mas também, permitir aos usuários experientes personalizar ações
frequentes.
8. Projeto estético minimalista: As interfaces devem ser o mais simples possível
e o fluxo de informações deve ocorrer de acordo com a necessidade do usuário.
5

9. Diagnosticar e corrigir erros: o sistema deve oferecer suporte aos usuários no
reconhecimento de problemas. As mensagens de erros devem ser claras,
indicando precisamente o problema e sugerindo soluções.
10. Ajuda e documentação: Caso necessário, a documentação de auxílio do
sistema deve ser fácil de usar e estar sempre disponível online.
Pereira (2011, p. 39) afirma que “uma avaliação heurística deve ser realizada por
equipes de três a cinco pessoas que, individualmente, percorrem a interface anotando os
problemas encontrados, as heurísticas desobedecidas e apresentando suas considerações em
relação à gravidade do problema". Soares (2004, p. 57) aponta que principal vantagem deste
método é "a não exigência de avaliadores com especialização em usabilidade e nem a
necessidade do envolvimento do usuário".
2.2 SYSTEM USABILITY SCALE (SUS)
Pereira (2011, p. 35) afirma que os métodos empíricos envolvem a participação de
usuários para a coleta de dados, que são posteriormente analisados pelos especialistas, para
identificar os problemas da interface. Enquanto que os métodos de inspeção em usabilidade
são aqueles onde os usuários não participam diretamente da avaliação que é feita por
especialistas que realizam a inspeção com base em algum critério que podem ser guidelines,
avaliação heurística ou percurso cognitivo.
Um método empírico muito adotado para a avaliação de usabilidade é o System
Usability Scale (SUS) (BROOKE, 1996). Este é um questionário simples e de rápida
aplicação que demonstra uma visão geral e subjetiva da avaliação da usabilidade de um
produto e, também, avalia a satisfação do usuário em relação ao mesmo. A ideia é aplicá-lo
após uma interação da qual se desejasse coletar medidas subjetivas de usabilidade. Porém,
uma desvantagem é que "os usuários poderiam estar fatigados, especialmente se já tiveram
dificuldades na interação com o produto" (LANUTTI et al., 2013, p.2). Este questionário é
composto por dez questões abrangendo uma visão global do usuário em relação ao sistema.
Para medir as opiniões utiliza-se a escala “Likert” que para cada pergunta têm-se como
resposta possível os valores: 1 (discordo plenamente), 2 (discordo), 3 (neutro), 4 (concordo) e
5 (concordo plenamente) (BROOKE, 1996).
Para calcular a pontuação do SUS, deve-se somar a contribuição de cada questão. O
valor de cada contribuição das questões ímpares (1, 3, 5, 7 e 9), que são as questões que
6

apresentam aspectos positivos, é dado pela fórmula: pontuação dada pelo usuário (entre 1 e 5)
menos 1. Para as questões pares (2, 4, 6,8 e 10), que representam fatores negativos do sistema,
a contribuição é dada pela fórmula: a pontuação dada pelo usuário (entre 1 e 5) menos 5.
Após determinado o valor de cada questão, é necessário somar todas as contribuições e
multiplicar por 2,5 para obter o resultado global do SUS, que deve estar inserido em uma
escala de 0 a 100. (BROOKE, 1996; MORAIS; SIMÕES, 2010).
Sistemas que conseguem, pelo menos, conseguem 90 pontos são considerados aqueles
com a melhor usabilidade possível. Os que atingem entre 80 e 90 pontos são considerados que
possuem uma usabilidade excelente. Os sistemas que atingem entre 70 e 80 pontos são os que
apresentam boa usabilidade, mas, que existem pontos a melhorar. Aqueles que atingem entre
60 e 70 pontos são considerados “ok” e que possuem grandes melhorias a serem realizadas e
por fim todos aqueles abaixo de 60 pontos que o grau de usabilidade é não aceitável
(BANGOr; KORTUN; MILLER, 2009).
3 ENCONTRABILIDADE
Robredo (2003, p.109) afirma que estamos vivendo em uma sociedade cuja quantidade
de informação cresce de modo exponencial e o acesso deve acontecer de forma cada vez mais
rápida, os sistemas de informação têm se tornado importante em todos os setores produtivos.
Entretanto, Bohmerwald (2005) afirma que na maior parte dos casos os sistemas de
informação não conseguem atingir o objetivo de proporcionar o acesso à informação,
influenciando diretamente na recuperação do conteúdo desejado.
É nesse contexto que o conceito de findability, ou encontrabilidade, emerge. Morville
(2005) afirma que “o conceito de encontrabilidade está ligado a qualidade de um objeto ser
localizável, ou navegável". Morville e Callender (2010) afirmam que a encontrabilidade se
refere à visibilidade da informação, a possibilidade de encontrá-la e localizá-la, as ações de
pesquisa e busca e encontrar objetos e respostas e (re) encontrar páginas, pessoas, lugares e
produtos.
Pereira (2011) correlaciona a encontrabilidade com a usabilidade ao sugerir que, em
sistemas de busca baseados em computador, a interface é o ponto de partida para o processo
de busca e recuperação da informação. Este é o elemento fundamental para garantir a
excelência do diálogo entre o sistema e o ser humano. E é a obediência aos princípios de
usabilidade que poderão ajudar nesse sentido.
7

Haller (2010) sugere que a encontrabilidade de determinadas informações pode ser
medida utilizando o método Keystroke Level Method (KLM), mensurando o tempo para se
encontrar cada informação. Esse método será detalhado a seguir.
3.1 KEYSTROKE LEVEL METHOD (KLM)
A técnica KLM tem como objetivo prever o tempo de execução de uma determinada
tarefa, a partir da soma dos tempos das ações que devem ser executadas para realizá-la
(SIQUEIRA, 2003, p. 44). Pettitt, Burnett e Stevens (2007, p.16) apontam que não é
necessário que a interface esteja implementada, basta que ela esteja especificada em detalhe
suficiente para determinar as seqüências de ações das tarefas de interesse, uma vez que a
técnica envolve decomposição das tarefas em módulos primitivos.
Germanakos e Belk (2016) sugerem que antes da realização da contagem de tempo, as
ações devem ser listadas, ordenadas e encadeadas utilizando algum método para documentar
fluxos de atividades tais como a análise das tarefas (WINKLER; PIMENTA, 2004). Haller
(2010) sugere que quando se trata de análise da encontrabilidade, o uso do KLM deve vir
associado a uma análise das tarefas para não só avaliar o tempo, mas principalmente avaliar o
caminho que o usuário percorre até de fato encontrar a informação de que ele precisa.
3.2 ANÁLISE DE TAREFAS
Análise de Tarefas é um método empírico que permite descrever e analisar como as
pessoas realizam suas atividades e este é um termo genérico para referenciar um conjunto de
métodos para descrever as tarefas das pessoas visando entender melhor os procedimentos para
sua realização (WINKLER; PIMENTA, 2004, p.3). Para Preece, Rogers e Sharp (2005), esse
método é um dos meios de investigar que tarefas as pessoas estão tentando realizar, o porquê
e como estão tentando realizá-las.
Para Schlemmer e Nassar (2011), o processo de analise de tarefa possui três etapas: (i)
a seleção das tarefas, (ii) a coleta dos dados e (iii) a divulgação dos resultados. A análise
inicia pela seleção das tarefas a serem analisadas; em seguida, na fase de coleta de dados, são
geradas a descrição da tarefa, a divisão de subtarefas da tarefa original e o fluxo que apresenta
a estruturação da tarefa; e, na última fase, apresentam-se os resultados em forma de requisitos
ou recomendações.
Winkler e Pimenta (2004, p.4) afirmam que existem vários métodos para realizar
análises da tarefa, entre as principais estão à análise hierárquica de tarefa e a análise cognitiva
8

de tarefa. Para os autores a análise hierárquica de tarefas – (HTA – Hierarchical Task
Analysis) é a representação básica da estrutura da tarefa e tem como objetivo entender as
competências e habilidades associadas às tarefas complexas e, usualmente, não repetitivas,
bem como auxiliar na identificação de problemas de desempenho. Já a análise cognitiva
preocupa-se em entender os processos cognitivos necessários para utilizar o sistema.
4 EXPERIÊNCIA DO USUÁRIO (UX)
Hassenzahl (2008) afirma que a experiência é uma reflexão em curso sobre eventos de
auto percepção que ocorrem constantemente. Mas, quando se trata de experiência do usuário,
não se tem interesse na experiência em si, mas, naquela que existe em relação aos produtos
interativos, que são instâncias da interação humano-sistema e que podem ser descritas de
forma temporal com um começo e um fim. Assim, o autor define UX (User Experience)
como um sentimento momentâneo, principalmente avaliativo (bom-mau), enquanto interage
com um produto. Por isso, a UX tem a atenção voltada para o produto (conteúdo, função,
apresentação e interação) e sua utilização pelos seres humanos e como estes se sentem (lado
subjetivo do uso do produto). Hassenzahl (2008) aponta, ainda, que há uma gama de desafios
relacionados a esta definição já que o foco no que é subjetivo sugere que a questão a ser
respondida é: como entrar nas cabeças das pessoas enquanto elas interagem com um produto?
Como podemos controlar a UX ao longo do tempo? Alguns destes desafios têm
consequências metodológicas diretas para a avaliação prática, que tornam difícil realizar
qualquer pesquisa neste sentido.
Stewart (2008) afirma que pessoas podem avaliar produtos interativos a partir de duas
dimensões diferentes: A primeira delas é a qualidade pragmática - que se refere à capacidade
do produto em apoiá-lo na realização de tarefas do tipo "Faça!", tais como fazer um
telefonema ou encontrar um livro em uma livraria. A qualidade pragmática foca na utilidade e
usabilidade do produto em relação às tarefas potenciais. Em contraste, a qualidade hedônica
se refere à capacidade do produto de apoiar a realização dos "Seja!", tais como ser competente
ou ser uma pessoa bem relacionada. A qualidade hedônica tem um foco sobre o “Ser”, isto é,
a questão do por que é que alguém se apropria e usa um produto particular. Aqui, as
necessidades humanas mais gerais vão além do instrumental e aparecem aspectos como a
necessidade de novidade e mudança, crescimento pessoal, auto expressão e/ou afinidade.

9

Rauschenberger, Cota e Thomaschewski (2013) afirmam que avaliar a qualidade, seja
pragmática, ou seja hedônica, da experiência do usuário não é simples e que um dos métodos
mais utilizados para fazer esse tipo de análise é o User Experience Questionnaire (UEQ)7. A
intenção deste questionário é captar a impressão global de um utilizador ao interagir com um
produto, abrangendo tanto a qualidade pragmática, quanto a hedônica.
O UEQ promove uma maneira simples e rápida para a avaliação da experiência do
usuário em relação a qualquer produto interativo. São 30 perguntas com respostas cujos
valores podem assumir sete posições na escala Likert, na qual um é a pior nota. As escalas são
projetadas para cobrir uma impressão abrangente de experiência do usuário e apoia a resposta
do usuário para expressar imediatamente sentimentos, impressões e atitudes que surgem
quando eles usam um produto.
5 METODOLOGIA
Quanto aos fins esta pesquisa é considerada como uma pesquisa descritiva que, de
acordo com Gil (2002), tem o objetivo de descrever as características de determinada
população ou fenômeno ou estabelecer relações entre variáveis. Quanto aos meios esta
pesquisa é classificada como pesquisa de campo que de acordo com Michel (2009, p.42)
caracteriza-se pela coleta de dados do ambiente natural com o objetivo de observar, criticar a
vida real, com base em teoria, para verificar como a teoria estudada se comporta na vida real.
Além de ser uma pesquisa comparativa, visto que será realizada a comparação entre os
métodos de avaliação escolhidos.
Esta também é uma pesquisa quali-quantitativa (MICHEL, 2009) que usa como
instrumentos de coleta de dados a avaliação heurística, a aplicação dos questionários SUS e
UEQ e aplicação do KLM em conjunto com a análise de tarefas. Para tanto foi utilizado o
sistema de gestão acadêmica da UFPE denominado Sig@. A realização da pesquisa seguiu as
etapas definidas na Figura 2.

7 http://www.ueq-online.org/

10

FIGURA 2: Etapas da Pesquisa

Fonte: Elaborado pelos autores, 2016.

Na primeira etapa foram escolhidos os seguintes métodos: (i) avaliação heurística, (ii)
avaliação de encontrabilidade usando KLM e análise de tarefas, (iii) teste de usabilidade
baseado no SUS e (iv) avaliação da experiência do usuário usando o UEQ. Esses métodos
foram escolhidos por existir uma literatura técnica abundante sobre os mesmos, o que
facilitaria o processo de avaliação.
Na segunda etapa foi delimitado o escopo das avaliações ao se determinar quais
funções do Sig@ seriam avaliadas. Foram escolhidas as funcionalidades histórico hiscolar e
grade de horário que são duas das funcionalidades mais utilizadas pelos discentes e que,
talvez, fossem mais simples de se avaliar pelo SUS e UEQ, cuja participação do usuário é
determinante.
Na terceira etapa foram conduzidas as avaliações. A avaliação heurística foi
executada por dois avaliadores, que avaliaram as funcionalidades selecionadas do Sig@ de
acordo com as 10 heurísticas de Nielsen, tendo como resultado para cada heurística atendida
(1 ponto), ou parcialmente atendida (0,5 ponto) ou não era atendida (0 ponto). Ao final da
avaliação individual, o resultado final foi calculado em uma reunião de consenso entre os dois
avaliadores. A avaliação de encontrabilidade foi realizada pelos mesmos avaliadores da etapa
anterior. Nesse caso, foi descrito o fluxo de cada tarefa e analisados quantos passos e ações
eram necessárias para encontrar a informação que se desejava. Também foi realizada uma
análise de tarefas de cada funcionalidade, sendo para isso utilizada a ferramenta Euterpe8 para
documentar esta avaliação. A aplicação dos questionários SUS e UEQ foram realizadas no
mesmo momento para quinze estudantes que responderam aos dois questionários. O SUS
utiliza o seu cálculo padrão já explanado na sessão do SUS enquanto que o UEQ possui uma
planilha própria que já calcula os valores. Ao final, para cada uma das avaliações foi
produzido um relatório final.
8 http://www.cs.vu.nl/~gerrit/gta/euterpe.html

11

Posteriormente, a partir desses relatórios é que foram mapeados quais aspectos da
relação humano-sistema foram investigados em cada avaliação e como esses aspectos foram
percebidos pelos avaliadores. Assim, a análise de dados se deu a partir da inferência sobre
quais métodos eram capazes de avaliar sete aspectos escolhidos com base no trabalho de
Fernandez, Insfran e Abrahão (2011) que listava os seguintes aspectos que as avaliações de
usabilidade mais auxiliavam: (i) interface, (ii) localização, (iii) efetividade, (iv) custo, (v)
intuitividade, (vi) utilidade e (vii) experiência. A pontuação final atribuída para cada aspecto é
dada por (N*10/X) onde N é a quantidade de características atendidas (N) e X representa
dividido o total de características.
O aspecto interfaces se refere a questões ligadas a disposição de elementos nos locais
corretos, uso de cores adequadas e outros elementos visuais que auxiliam o usuário na
utilização do sistema. Segundo os autores esse elemento se subdivide em seis características
(X=6) que são: padronização visual, disposição dos elementos na tela, uso de elementos de
design em cores e imagens, vinculação entre elementos visuais e signos, feedback e elementos
visuais consideram o modelo mental do usuário.
O aspecto localização se refere a organização do conteúdo e/ou funcionalidades do
sistema e quão difícil é para o usuário, encontrar o que ele precisa no sistema. Para este
aspecto foram listadas quatro características (X=4): informar ao usuário sua localização atual
no sistema, identificar o caminho que o usuário percorreu até encontrar o que se deseja,
organização do conteúdo/funcionalidades de acordo com categorias e identificar se há mais de
um caminho para encontrar o que se deseja.
O aspecto efetividade se refere a capacidade do sistema em atender as necessidades do
usuário e aqui temos três categorias (X=3): É necessário apenas uma utilização para se
realizar a atividade, a atividade não faz parte de outras atividades maiores, o sistema auxilia o
usuário na prevenção de erros.
O aspecto custo representa quanto esforço e tempo o usuário gastaria para realizar
suas tarefas no sistema. Este aspecto se subdivide em três características (X=3): quantidade
tempo para realizar uma atividade, quantidade de ações (cliques e digitações), complexidade
técnica,
O aspecto intuitividade avalia a capacidade de o sistema conduzir o usuário a realizar
a ação desejada de modo que ele não tenha que “aprender” o caminho tomado e sim inferi-lo.
Para este aspecto foram listadas quatro características (X=4): necessidade de conhecimento
12

prévio, tempo de aprendizado, foi necessário auxílio para realizar a atividade e se a atividade
é fácil de se realizar.
O aspecto utilidade se refere a quanto o sistema é necessário para o usuário resolver
problemas ligados ao mundo real Este aspecto se subdivide em quatro características (X=4):
representa uma ação do mundo real, se faz sentido para o usuário, se é a principal razão para a
utilização do sistema e se o sistema é a melhor forma de realizar a atividade dentre todas as
opções.
Por fim, o aspecto experiência se refere ao quão agradável foi a experiência do
usuário na utilização do sistema e se subdivide em quatro características (X=4): o quão
agradável foi o uso do sistema? Se o usuário voltaria a usá-lo? Se o usuário recomendaria o
sistema a alguém? E se o usuário pode comparar este sistema a outro?
A partir desses sete aspectos, cada relatório final foi analisado e se verificou em quais
aspectos cada avaliação se enquadra, apresentando os resultados em forma de gráficos de
radar. Adicionalmente, foram explanados pontos fortes e fracos de cada método de avaliação
empregado. Vale ressaltar que o relatório final de cada método de avaliação era diferente em
estrutura e formato. Para a avaliação heurística, foram analisados os relatórios dos dois
avaliadores, separadamente, com detalhes sobre onde cada uma das 10 heurísticas foi
desrespeitada e o relatório da reunião dos avaliadores em que se tem a convergência da
avaliação. Para a avaliação da encontrabilidade, o resultado final era dado por uma figura, que
representava um fluxo de atividades para se realizar a tarefa e a análise da figura. Do teste de
usabilidade SUS, foram analisados todos os 15 formulários respondidos pelos alunos e o
formulário que aglutinava à média de todas as questões e que deu origem a pontuação final do
sistema. Para a avaliação de encontrabilidade usando o UEQ foram recebidos os 15
questionários respondidos e foi gerado um gráfico de barras que aglutinava o resultado final.
6 RESULTADOS E DISCUSSÕES
Os gráficos contendo a análise de cada um dos métodos de avaliação, sob a
perspectiva dos sete aspectos escolhidos, podem ser visto na Figura 3. Analisando os diversos
tipos de avaliações, quando se trata de interação humano-sistema, pode-se observar na Figura
3 que os quatro métodos escolhidos possuem direcionamentos diferentes sobre o que está
sendo avaliado.
A Avaliação Heurística de Nielsen (Figura 3a) se preocupa mais com a construção
visual do produto e com a percepção do usuário sobre o sistema, esse fato pode ser percebido
13

no aspecto interface onde cinco das seis características foram atendidas. Destaca-se que este
método ignora completamente aspectos relativos a experiência da utilização do sistema pelo
usuário, assim como o custo, e auxilia pouco no entendimento da utilidade do sistema para o
usuário e a localização de informação/funcionalidade no sistema.
A avaliação de encontrabilidade utilizando o KLM (Figura 3b) tem uma atenção maior
para identificar se determinada funcionalidade/relatório é facilmente encontrada e qual é o
esforço/tempo que o usuário leva para encontrá-lo, ambos com todas as características
completamente satisfeitas. Este método ignora muitos aspectos ligados ao produto e a
interação do usuário com o mesmo. Embora o método identifique se um usuário concluiu ou
não uma tarefa (efetividade), não há uma análise a respeito da completude daquela tarefa, ou é
necessária a realização de várias tarefas para atingir um único objetivo do usuário.
FIGURA 3: Análise dos Métodos de Avaliação

Fonte: Elaborado pelos Autores, 2016.

14

O Teste de Usabilidade baseado no SUS (Figura 3c) é largamente orientado a entender
a relação usuário-produto, de um ponto de vista subjetivo, que considera apenas as impressões
do usuário na experiência de uso e relativo a dinâmica do sistema e, assim como os outros
métodos, ignorando a utilidade do sistema para o usuário.
Por fim a avaliação de experiência do usuário baseada no UEQ (Figura 3d) foi o
método, que mesmo parcialmente, atendeu a uma maior quantidade de aspectos. Este também
é um método que apresenta certa preocupação em determinar se o usuário consegue completar
as tarefas e se as funcionalidades executadas tem valor para o usuário. Apesar de ser mais
completo, o método ainda deixa a desejar em questões mais centrais da interface, da
percepção do usuário sobre os elementos visuais e de uso do sistema e se o
conteúdo/funcionalidade do sistema é de fácil utilização pelos usuários.
Destaca-se que os métodos que envolvem o usuário estão mais ligados a responder
certos aspectos subjetivos tais como a experiência do uso, se o sistema é útil para as suas
tarefas e se é eficiente. Enquanto que critérios mais técnicos, como as heurísticas, avaliam
elementos de design ou de arquitetura de informação. Desta forma, verifica-se que aplicar
diversos métodos de avaliação ainda é mais eficaz do que a utilização de apenas um deles,
quando se deseja avaliar diversos aspectos da interação humano-sistema. A Figura 4 apresenta
o gráfico da junção de todas as abordagens enquadradas nos sete aspectos.
O resultado da utilização de todos os métodos é visivelmente mais abrangente do que
qualquer um dos métodos utilizado isoladamente (Figura 4). Porém, dependendo do aspecto
da interação humano-sistema que se deseja avaliar, a utilização de um único método pode ser
suficiente, menos custosa e mais simples.

15

FIGURA 4: Junção do resultado da aplicação dos 4 métodos

Fonte: Elaborado pelos Autores, 2016.
Ressalta-se que, caso o SUS fosse retirado desta pesquisa, o gráfico final (Figura 4)
não sofreria alteração alguma, uma vez que o SUS pode ser substituído, quase que
integralmente, pelo UEQ (Figuras 3c e 3d) e nos pontos que o SUS é mais completo que o
UEQ, os outros dois métodos se sobrepõem a ele. Assim, o SUS poderia ser retirado essa
análise sem prejuízos.
7 CONSIDERAÇÕES FINAIS
Os diversos métodos para avaliação de interação humano-sistema, analisados nesta
pesquisa, compõe um conjunto de técnicas úteis e que observam aspectos específicos desta
relação usuário-sistema.
Este trabalho traz como contribuições a análise para determinar em que ocasiões os
métodos escolhidos são mais ou menos adequados e quais as vantagens de se combinar mais
de um método. Pode-se perceber que nem todos os métodos de avaliação, principalmente
aqueles que capturam a opinião dos usuários com base em questionários, capturam a relação
usuário-informação de forma detalhada o suficiente para se entender qual é o real problema da
interface. O que pode ser compreendido é que há problema em um determinado aspecto do
sistema, mas não se sabe exatamente qual é o problema, sendo necessária a utilização de
outras técnicas para fazer essas identificações.
Realizar avaliações da encontrabilidade a partir da análise de tarefas e KLM se mostra
uma avaliação interessante porque se é analisado o caminho que o usuário seguiu no sistema e
16

o tempo de execução das tarefas e não apenas a quantidade de cliques e digitações que o
mesmo precisa para encontrar a informação.
A análise da experiência do usuário através do UEQ se mostra útil e prático para se ter
noção geral (quali-quanti) da percepção do usuário em relação ao sistema. Embora o mesmo
não apresente dados qualitativos detalhados dos problemas que o usuário encontra em um
sistema, certamente indica pontos fracos que podem direcionar as avaliações de especialistas.
Por outro lado, ele se mostra uma ferramenta bem eficiente para realizar comparações e
criações de benchmarks de produtos avaliados tornando-se uma boa opção para quem trabalha
com pesquisa de mercado, uma vez que rapidamente o UEQ promove um resultado
quantitativo sobre a opinião de um grupo de usuários sobre um determinado produto.
Nesta pesquisa existem limitações ao estudo que foram minimizadas, na medida do
possível, mas que ainda assim podem interferir no resultado final. Iniciando pelas ameaças a
validade

interna

tem-se

como

principal

viés

determinar

se

o

processo

de

avaliação/comparação utilizado é adequado. Não foi encontrado trabalho algum que
propusesse uma abordagem para análise/comparação entre métodos de avaliação interaçãohumano sistema. Outros artigos que comparavam tais métodos faziam explanações
qualitativas sobre os mesmos realçando os pontos fortes e fracos. Nessa pesquisa, a análise foi
feita com base no relatório final de cada método e nos sete aspectos escolhidos definidos por
Fernandez, Insfran e Abrahão (2011).
Outra limitação é referente ao teste que envolvia usuários (SUS e UEQ) que foram
feitos por alunos experientes no sistema, fazendo com que haja a possibilidade de que os
resultados primários obtidos tenham uma diferença dos resultados da aplicação a uma amostra
aleatória de usuários. Entretanto, vale ressaltar que esse viés é minimizado uma vez que foram
avaliados quais são os fatores destacados por cada método de avaliação e não os resultados
em si.

